{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO_GAE_LLCont_sigma_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1VqP1NKsPe",
        "outputId": "7b4c9ebe-7db0-4a7f-b1c6-ac6db1a80566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep 30 09:06:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG0sRYAbKtja",
        "outputId": "c68f0030-df9a-4613-82a7-aafc10991e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXEex1K2K0Se"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SRyzt5S_75J",
        "outputId": "6e7a109a-a51a-4881-e188-664ab73f34f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://github.com/yandexdataschool/Practical_RL/issues/256\n",
        "    !pip uninstall tensorflow --yes\n",
        "    !pip uninstall keras --yes\n",
        "    !pip install tensorflow-gpu==1.13.1\n",
        "    !pip install keras==2.2.4\n",
        "    \n",
        "    if not os.path.exists('.setup_complete'):\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "        !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "!pip install box2d-py\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "Uninstalling Keras-2.4.3:\n",
            "  Successfully uninstalled Keras-2.4.3\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 58.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (50.3.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.0)\n",
            "Installing collected packages: mock, tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.4\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 144619 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.6_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n",
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQAUCblQ_75N"
      },
      "source": [
        "### Let's make a TRPO!\n",
        "\n",
        "In this notebook we will write the code of the one Trust Region Policy Optimization.\n",
        "As usually, it contains a few different parts which we are going to reproduce.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzsdr5_8_75O"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import gym\n",
        "import numpy as np\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzq9yG7_75R",
        "outputId": "c97294c2-1e9c-43ad-9c56-beccb28b8563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "env.reset()\n",
        "\n",
        "dim_state = env.observation_space.shape[0]\n",
        "print(\"Size of State Space ->  {}\".format(dim_state))\n",
        "\n",
        "dim_action = env.action_space.shape[0]\n",
        "print(\"Size of Action Space ->  {}\".format(dim_action))\n",
        "\n",
        "lower_bound = env.action_space.low[0]\n",
        "upper_bound = env.action_space.high[0]\n",
        "\n",
        "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
        "print(\"Max Value of Action ->  {}\".format(upper_bound))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of State Space ->  8\n",
            "Size of Action Space ->  2\n",
            "Min Value of Action ->  -1.0\n",
            "Max Value of Action ->  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AS5Om-4_75T",
        "outputId": "4a9caa5b-879a-4328-9d44-1a2caa607c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(env.render('rgb_array'))\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgvVN9_z_75W"
      },
      "source": [
        "### Step 1: Defining a network\n",
        "\n",
        "With all it's complexity, at it's core TRPO is yet another policy gradient method. \n",
        "\n",
        "This essentially means we're actually training a stochastic policy $ \\pi_\\theta(a|s) $. \n",
        "\n",
        "And yes, it's gonna be a neural network. So let's start by defining one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0sJTpTj_75X"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Unknown Time dimention = None\n",
        "\n",
        "# input tensors\n",
        "obs_ph  = tf.placeholder(shape=(None, dim_state), dtype=tf.float32)\n",
        "\n",
        "# \n",
        "p_beta_ph = tf.placeholder(shape=(), dtype=tf.float32)\n",
        "v_beta_ph = tf.placeholder(shape=(), dtype=tf.float32)\n",
        "\n",
        "# Actions that we made\n",
        "actions_ph   = tf.placeholder(shape=(None, dim_action), dtype=tf.float32)\n",
        "\n",
        "# Previous Model \"mu\" prediction\n",
        "old_mu_ph    = tf.placeholder(shape=(None, dim_action), dtype=tf.float32)\n",
        "old_V_ph     = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Action probabilities from previous iteration\n",
        "old_probs_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# GAE\n",
        "advantage_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Cumulative Return \"G = r + gamma*r' + gamma^2*r'' + ...\"\n",
        "c_returns_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Sigma is an input parameter!\n",
        "sigma_sq = (2 ** 2) * tf.ones((dim_action, ), dtype=tf.float32)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IVhWlCeCj3"
      },
      "source": [
        "Multivariate Gaussian PDF: \n",
        "\n",
        "TF and np functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmzQntJ_I-gN"
      },
      "source": [
        "def tf_normal(s, mu, sigma_sq):\n",
        "    exp_term   = tf.math.exp( - tf.reduce_sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = tf.math.sqrt( tf.math.pow(2 * np.pi, dim_action) * tf.reduce_prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "def normal(s, mu, sigma_sq):\n",
        "    exp_term   = np.exp( - np.sum( np.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = np.sqrt( np.pow(2 * np.pi, dim_action) * np.prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "def sample_action(mu, sigma_sq):\n",
        "    action = mu + np.sqrt(sigma_sq) * np.random.randn( mu.shape[0] )\n",
        "    return action\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOPs8OEn_75a",
        "outputId": "05713744-634a-4685-a67b-c64ab1757062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def denselayer(name, x, out_dim, nonlinearity=None):\n",
        "    with tf.variable_scope(name):\n",
        "        if nonlinearity is None:\n",
        "            nonlinearity = tf.identity\n",
        "\n",
        "        W = tf.get_variable('W', shape=[x.shape[1], out_dim])\n",
        "        b = tf.get_variable('b', shape=[out_dim], \n",
        "                            initializer = tf.compat.v1.random_normal_initializer(mean=0.0, stddev=0.05))\n",
        "        o = nonlinearity(tf.matmul(x, W) + b)\n",
        "        return o\n",
        "\n",
        "\n",
        "# Interactive Session\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# NN for prediction of mu\n",
        "nn = denselayer(\"policy_layer_1\", obs_ph, 64, tf.nn.tanh)\n",
        "nn = denselayer(\"policy_layer_2\", nn, 64, tf.nn.tanh)\n",
        "nn = denselayer(\"policy_layer_3\", nn, 64, tf.nn.tanh)\n",
        "mu = denselayer(\"policy\", nn, dim_action, tf.nn.tanh)\n",
        "\n",
        "# Actions\n",
        "probs_ph = tf_normal(actions_ph, mu, sigma_sq)\n",
        "\n",
        "# NN for prediction of V\n",
        "nn  = denselayer(\"value_layer_1\", obs_ph, 64, tf.nn.relu)\n",
        "nn  = denselayer(\"value_layer_2\", nn, 64, tf.nn.relu)\n",
        "nn  = denselayer(\"value_layer_3\", nn, 64, tf.nn.relu)\n",
        "V   = denselayer(\"value\", nn, 1, None)\n",
        "\n",
        "# Get Trainable Variables\n",
        "train_vars = tf.trainable_variables()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auf2Au2__758"
      },
      "source": [
        "### Step 3: loss functions\n",
        "\n",
        "Now let's define the loss functions and constraints for actual TRPO training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EkGpySi_759"
      },
      "source": [
        "Advantage:\n",
        "$$A_{\\theta_{old}}(s_{i},a_{i})=G_{\\theta_{old}}(s_{i},a_{i})-V_{\\theta_{old}}(s_{i})$$\n",
        "\n",
        "where the gain function is\n",
        "$$G_{\\theta_{old}}(s_{i},a_{i})=\\sum_{j=i}^{T}\\gamma^{j-i}r_{j}$$\n",
        "\n",
        "The surrogate reward should be\n",
        "$$J_{surr}= {1 \\over N} \\sum\\limits_{i=0}^N \\frac{\\pi_{\\theta}(s_i, a_i)}{\\pi_{\\theta_{old}}(s_i, a_i)}\n",
        "A_{\\theta_{old}}(s_{i},a_{i})$$\n",
        "\n",
        "Clip Loss Function\n",
        "$$L_{\\theta_{old}}^{CLIP}(\\theta)=\\frac{1}{N}\\sum\\limits _{i=0}^{N}\\min\\left\\{ \\frac{\\pi_{\\theta}(s_{i},a_{i})}{\\pi_{\\theta_{old}}(s_{i},a_{i})}A_{\\theta_{old}}(s_{i},a_{i}),\\ g\\left(\\epsilon,A_{\\theta_{old}}(s_{i},a_{i})\\right)\\right\\}$$\n",
        "\n",
        "where function\n",
        "$$g(\\epsilon,A)=\\begin{cases}\n",
        "(1+\\epsilon)A & ,\\text{ if }A\\geq0\\\\\n",
        "(1-\\epsilon)A & ,\\text{ o.w.}\n",
        "\\end{cases}$$\n",
        "\n",
        "Or alternatively, minimize the surrogate loss:\n",
        "$$ L_{surr} = - L_{\\theta_{old}}^{CLIP}(\\theta) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGzd6WwT_76B"
      },
      "source": [
        "# Compute surrogate loss: negative importance-sampled policy gradient\n",
        "batch_size = tf.cast(tf.shape(mu)[0], tf.float32)\n",
        "\n",
        "# select probabilities of chosen actions\n",
        "probs_all     = tf.reshape(probs_ph, [-1])\n",
        "old_probs_all = tf.reshape(old_probs_ph, [-1])\n",
        "ratio_ph      = probs_all / old_probs_all\n",
        "\n",
        "# clipping pattern\n",
        "epsilon = 0.2\n",
        "clippling_pattern = tf.minimum((1 - epsilon) * advantage_ph, 0) +\\\n",
        "                    tf.maximum((1 + epsilon) * advantage_ph, 0)\n",
        "\n",
        "# Clipped Loss\n",
        "L_surr = tf.reduce_mean( tf.minimum(ratio_ph * advantage_ph, clippling_pattern) )\n",
        "\n",
        "\n",
        "# Value loss\n",
        "V_objective = tf.reduce_mean( tf.math.square( V[:,0] - c_returns_ph ) )\n",
        "\n",
        "ss_sq    = tf.reduce_mean( tf.math.square( old_V_ph - c_returns_ph ) )\n",
        "kl_value = tf.reduce_mean( tf.math.square( V[:0] - old_V_ph ) ) / (2 * ss_sq)\n",
        "\n",
        "V_loss = V_objective + v_beta_ph * kl_value\n",
        "train_V_loss = tf.train.AdamOptimizer(1e-4).minimize(V_loss)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imv9XYia_76F"
      },
      "source": [
        "We can ascend these gradients as long as our $\\pi_\\theta(a|s)$ satisfies the constraint\n",
        "$$E_{s,\\pi_{\\Theta_{t}}}\\Big[KL(\\pi(\\Theta_{t}, s) \\:||\\:\\pi(\\Theta_{t+1}, s))\\Big] < \\alpha$$\n",
        "\n",
        "\n",
        "\n",
        "For multivariate Guassian distributions, we have\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "KL\\left(\\pi_{t}(\\cdot|s)\\:||\\:\\pi_{t+1}(\\cdot|s)\\right)&=&\\frac{1}{2}\\left\\{ -k+Tr\\left[\\Sigma_{t+1}^{-1}\\Sigma_{t}\\right]+(\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})+\\ln\\frac{\\det(\\Sigma_{t+1})}{\\det(\\Sigma_{t})}\\right\\} \\\\(\\Sigma_{t+1}=\\Sigma_{t})&=&\\frac{1}{2}\\left\\{ (\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})\\right\\} \\\\&=&\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[\\mu_{t+1}-\\mu_{t}]_{i}}{[\\sigma_{t+1}]_{i}}\\right)^{2}\n",
        "\\end{eqnarray*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvAuUZZU_76G",
        "outputId": "b03f082b-925c-4def-a39e-bd17bc2c92e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Compute Kullback-Leibler divergence (see formula above)\n",
        "# Note: you need to sum KL and entropy over all actions, not just the ones agent took\n",
        "\n",
        "kl_policy = 0.5 * tf.reduce_sum( tf.math.square(mu - old_mu_ph) / (2 * sigma_sq))\n",
        "kl_policy /= batch_size\n",
        "\n",
        "# Compute policy entropy\n",
        "log_probs_all = tf.math.log(probs_all + 1e-5)\n",
        "entropy       = - tf.reduce_sum(probs_all * log_probs_all) / batch_size\n",
        "\n",
        "# Goal is to maximize: L_surr, minimize beta_ph * kl, maximize entropy\n",
        "# Since we use minimizer, we have\n",
        "policy_loss       = -L_surr + p_beta_ph * kl_policy - entropy\n",
        "train_Policy_loss = tf.train.AdamOptimizer(1e-4).minimize(policy_loss)\n",
        "\n",
        "# No variable depends on the following losses\n",
        "# Used only for progress tracking\n",
        "#losses = [L_surr, kl_policy, entropy, kl_value]\n",
        "losses = [kl_policy, kl_value]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BePcHv1K-u5"
      },
      "source": [
        "# Initialize TF\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjOp0ljT34VM"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt64G5Pi3xfO",
        "outputId": "63dbe721-69c0-4f49-878f-f07cfa0b64df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Restore variables from disk.\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, \"model.ckpt\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_rSvyFq355u"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljE2-68L_75f"
      },
      "source": [
        "### Step 2: Actions and rollouts\n",
        "\n",
        "In this section, we'll define functions that take actions $ a \\sim \\pi_\\theta(a|s) $ and rollouts $ \\langle s_0,a_0,s_1,a_1,s_2,a_2,...s_n,a_n \\rangle $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TaUC34w_75f"
      },
      "source": [
        "def act(obs, sample = True):\n",
        "    \"\"\"\n",
        "    Samples action from policy distribution (sample = True) or takes most likely action (sample = False)\n",
        "    :param: obs - single observation vector\n",
        "    :param sample: if True, samples from \\pi, otherwise takes most likely action\n",
        "    :returns: mu, V, action, prob\n",
        "    \"\"\"\n",
        "    # obs.reshape((1, -1)) makes batch first: [[obs]]\n",
        "    feed_dict = {obs_ph: obs.reshape((1, -1))}\n",
        "    mu_eval, V_eval   = sess.run([mu, V], feed_dict = feed_dict)\n",
        "    mu_eval = mu_eval[0]\n",
        "    V_eval  = V_eval[0,0]\n",
        "\n",
        "    # Sample action\n",
        "    action = sample_action(mu_eval, sigma_sq.eval()) if sample == True else mu_eval\n",
        "\n",
        "    # Add actions to the dictionary\n",
        "    feed_dict[actions_ph] = action[None]\n",
        "    prob = sess.run(probs_ph, feed_dict = feed_dict)[0]\n",
        "\n",
        "    return mu_eval, V_eval, action, prob"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX7Wf5kj_75o"
      },
      "source": [
        "Compute cummulative reward just like you did in vanilla REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDLeSmTX_75w"
      },
      "source": [
        "**Rollout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbJKrqLFCsNy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_GAE(r, v, v_p, gamma=1, gae_param=1):\n",
        "    n   = np.shape(r)[0]\n",
        "    gae = np.zeros(n, dtype=np.float32)\n",
        "\n",
        "    d = np.zeros(n, dtype = np.float32)\n",
        "    d[:-1] = r[:-1] + gamma * v[1:] - v[:-1]\n",
        "    d[-1]  = r[-1]  + gamma * v_p   - v[-1]\n",
        "    \n",
        "    gae[n-1] = d[n-1]\n",
        "    for i in reversed(range(n-1)):\n",
        "        gae[i] = d[i] + ( gae_param * gamma ) * gae[i+1]\n",
        "\n",
        "    return gae"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UFon-4g_75x"
      },
      "source": [
        "# A valid path in a rollout must either:\n",
        "# end up in a \"done\" state or\n",
        "# exceed the allowed steps\n",
        "# NOTE: We might end up with a single path that exceeds steps limit !\n",
        "\n",
        "def rollout(env, act, sample=True, gamma=1, gae_param=1, max_pathlength=3000, n_timesteps=10000):\n",
        "    \"\"\"\n",
        "    Generate rollouts for training.\n",
        "    :param: env - environment in which we will make actions to generate rollouts.\n",
        "    :param: act - the function that can return policy and action given observation.\n",
        "    :param: max_pathlength - maximum size of one path that we generate.\n",
        "    :param: n_timesteps - total sum of sizes of all pathes we generate.\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "\n",
        "    total_timesteps = 0\n",
        "\n",
        "    while total_timesteps < n_timesteps:\n",
        "        obervations, mu_evals, V_evals, actions, rewards, action_probs = [], [], [], [], [], []\n",
        "        obervation = env.reset()\n",
        "        \n",
        "        for _ in range(max_pathlength):\n",
        "            mu_eval, V_eval, action, action_prob = act(obervation, sample)\n",
        "\n",
        "            obervations.append(obervation)\n",
        "            mu_evals.append(mu_eval)\n",
        "            V_evals.append(V_eval)\n",
        "            actions.append(action)\n",
        "            action_probs.append(action_prob)\n",
        "\n",
        "            obervation, reward, done, _ = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            total_timesteps += 1\n",
        "\n",
        "            if done or total_timesteps == n_timesteps:\n",
        "                v_p = 0 if done else act(obervation)[1]\n",
        "                \n",
        "                np_values  = np.array(V_evals)\n",
        "                np_rewards = np.array(rewards)\n",
        "                \n",
        "                np_gae = get_GAE(np_rewards, np_values, v_p, gamma, gae_param)\n",
        "                cummulative_rewards = np_values + np_gae\n",
        "\n",
        "                path = {\"observations\": np.array(obervations),\n",
        "                        \"mu_evals\": np.array(mu_evals),\n",
        "                        \"values\": np_values,\n",
        "                        \"actions\": np.array(actions),\n",
        "                        \"action_probs\":  np.array(action_probs),\n",
        "                        \"cumulative_returns\": cummulative_rewards,\n",
        "                        \"GAE\": np_gae,\n",
        "                        \"reward\": np.sum(np_rewards),\n",
        "                        }\n",
        "                paths.append(path)\n",
        "                break\n",
        "    # outputs List of Dictionaries (feed to nn)\n",
        "    return paths"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrH9E9sk_76c"
      },
      "source": [
        "##### Step 5: Main PPO loop\n",
        "\n",
        "Here we will train our network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiROykhhcUp-"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import trange\n",
        "import pickle\n",
        "\n",
        "eps = 0.01\n",
        "\n",
        "gamma     = 0.99\n",
        "gae_param = 0.95\n",
        "\n",
        "p_beta = 100\n",
        "v_beta = 100\n",
        "\n",
        "# Number of Gradient descent iterations for policy\n",
        "grad_iters = 5\n",
        "\n",
        "# To store average reward history of last few episodes\n",
        "avg_reward_list = []\n",
        "std_reward_list = []\n",
        "\n",
        "#Load \n",
        "with open(\"avg_reward_list.txt\", \"rb\") as fp:   # Unpickling\n",
        "    avg_reward_list = pickle.load(fp)\n",
        "\n",
        "with open(\"std_reward_list.txt\", \"rb\") as fp:   # Unpickling\n",
        "    std_reward_list = pickle.load(fp)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgJmJFz1_76d",
        "outputId": "18db7d94-f83c-4664-b7a3-2cb5dc1ada5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "#import time\n",
        "#from itertools import count\n",
        "#from collections import OrderedDict\n",
        "#num_epis_total = 0    # number of played episodes\n",
        "#start_time = time.time()\n",
        "\n",
        "\n",
        "done_iters = len(avg_reward_list)\n",
        "iters  = 100\n",
        "x_axis = list( range(1,done_iters + 1) )\n",
        "\n",
        "for i in trange(iters):\n",
        "\n",
        "    # Generating paths.\n",
        "    paths = rollout(env, act, sample=True, gamma=gamma, gae_param=gae_param)\n",
        "    \n",
        "    # Load feed_dict and old_weights\n",
        "    observations = np.concatenate([path[\"observations\"] for path in paths])\n",
        "    old_mu_eval  = np.concatenate([path[\"mu_evals\"] for path in paths])\n",
        "    old_V_eval   = np.concatenate([path[\"values\"] for path in paths])\n",
        "    actions      = np.concatenate([path[\"actions\"] for path in paths])\n",
        "    old_probs    = np.concatenate([path[\"action_probs\"] for path in paths])\n",
        "    c_returns    = np.concatenate([path[\"cumulative_returns\"] for path in paths])\n",
        "    GAE          = np.concatenate([path[\"GAE\"] for path in paths])\n",
        "    \n",
        "    feed_dict_policy = {obs_ph: observations,\n",
        "                        old_mu_ph: old_mu_eval,\n",
        "                        actions_ph: actions,\n",
        "                        old_probs_ph: old_probs,\n",
        "                        advantage_ph: GAE,\n",
        "                        c_returns_ph: c_returns,\n",
        "                        p_beta_ph: p_beta,}\n",
        "\n",
        "    for _ in range(grad_iters):\n",
        "        # Train Policy loss\n",
        "        sess.run(train_Policy_loss, feed_dict = feed_dict_policy)\n",
        "\n",
        "    feed_dict_value = {obs_ph: observations,\n",
        "                       c_returns_ph: c_returns,\n",
        "                       old_V_ph: old_V_eval,\n",
        "                       v_beta_ph: v_beta}\n",
        "\n",
        "    for _ in range(grad_iters):\n",
        "        # Train State Value loss\n",
        "        sess.run(train_V_loss, feed_dict = feed_dict_value)\n",
        "    \n",
        "    feed_dict_loss = feed_dict_policy\n",
        "    for k in feed_dict_value.keys():\n",
        "        feed_dict_loss[k] = feed_dict_value[k]\n",
        "\n",
        "    # Report current progress\n",
        "    kl_policy_v, kl_value_v = sess.run(losses, feed_dict = feed_dict_loss)\n",
        "    \n",
        "    # Update soft constraint regulizers\n",
        "    if kl_policy_v >= 1.5 * eps:\n",
        "        p_beta *= 2\n",
        "    if kl_policy_v <= eps / 1.5:\n",
        "        p_beta /= 2\n",
        "\n",
        "    if kl_value_v >= 1.5 * eps:\n",
        "        v_beta *= 2\n",
        "    if kl_value_v <= eps / 1.5:\n",
        "        v_beta /= 2\n",
        "    \n",
        "    episode_rewards = np.array([path[\"reward\"] for path in paths])\n",
        "    \n",
        "    avg_reward_list.append(episode_rewards.mean())\n",
        "    std_reward_list.append(episode_rewards.std())\n",
        "\n",
        "    #Print Figure\n",
        "    x_axis.append(done_iters + i + 1)\n",
        "\n",
        "    clear_output(True)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle('Mean and Std Reward')\n",
        "    ax1.plot(x_axis, avg_reward_list)\n",
        "    ax2.plot(x_axis, std_reward_list)\n",
        "    ax1.set(xlabel='Episode', ylabel='Mean Reward')\n",
        "    ax2.set(xlabel='Episode', ylabel='Std Reward')\n",
        "    fig.tight_layout(pad=3.0)\n",
        "    plt.show()\n",
        "\n",
        "    #stats = OrderedDict()\n",
        "    #num_epis_total += len(episode_rewards)\n",
        "\n",
        "    #stats[\"Total number of episodes\"] = num_epis_total\n",
        "    #stats[\"Average sum of rewards per episode\"] = episode_rewards.mean()\n",
        "    #stats[\"Std of rewards per episode\"] = episode_rewards.std()\n",
        "    #stats[\"Entropy\"] = entropy\n",
        "    #stats[\"Time elapsed\"] = \"%.2f mins\" % ((time.time() - start_time)/60.)\n",
        "    #stats[\"KL between old and new distribution\"] = kl\n",
        "    #stats[\"Surrogate loss\"] = L_surr\n",
        "\n",
        "    #for k, v in stats.items():\n",
        "    #    print(k + \": \" + \" \" * (40 - len(k)) + str(v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [01:25<1:10:03, 42.89s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYNm-Ga_q36w"
      },
      "source": [
        "# Save to disk\n",
        "saver = tf.train.Saver()\n",
        "saver.save(sess, \"model.ckpt\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(\"avg_reward_list.txt\", \"wb\") as fp:\n",
        "    pickle.dump(avg_reward_list, fp)\n",
        "\n",
        "with open(\"std_reward_list.txt\", \"wb\") as fp:\n",
        "    pickle.dump(std_reward_list, fp)    "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_T5qDKCx17K",
        "outputId": "2bb27be4-6bf2-4250-8874-14c000182ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "paths = rollout(env, act, sample=True)\n",
        "print(np.mean([path['reward'] for path in paths]))\n",
        "\n",
        "x = [path['reward'] for path in paths]\n",
        "plt.hist(x, bins = 50)\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-3.4328111809854303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEBoGP13IoC8"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KXLiWZYben0"
      },
      "source": [
        "def evaluate(env, n_games=1):\n",
        "    \"\"\"Plays an a game from start till done, returns per-game rewards \"\"\"\n",
        "\n",
        "    game_rewards = []\n",
        "    for _ in range(n_games):\n",
        "        # initial observation and memory\n",
        "        observation = env.reset()\n",
        "\n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            mu_eval, V_eval, action, prob = act(observation, sample=True)\n",
        "            observation, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        game_rewards.append(total_reward)\n",
        "    return game_rewards"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6bjqpBtl9_c",
        "outputId": "b59b81d0-72fc-4bf0-ee45-260efdf40f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gym.wrappers\n",
        "\n",
        "with gym.wrappers.Monitor(env, directory=\"videos\", force=True) as env_monitor:\n",
        "    final_rewards = evaluate(env_monitor, n_games=5)\n",
        "\n",
        "print(\"Final rewards\", np.mean(final_rewards))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final rewards -0.07316073364769124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IXb-scZdj2I"
      },
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(video_names[-1]))  # You can also try other indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6mISEoL_76h"
      },
      "source": [
        "# Homework option I: better sampling (10+pts)\n",
        "\n",
        "In this section, you're invited to implement a better rollout strategy called _vine_.\n",
        "\n",
        "![img](https://s17.postimg.cc/i90chxgvj/vine.png)\n",
        "\n",
        "In most gym environments, you can actually backtrack by using states. You can find a wrapper that saves/loads states in [the mcts seminar](https://github.com/yandexdataschool/Practical_RL/blob/master/week10_planning/seminar_MCTS.ipynb).\n",
        "\n",
        "You can read more about in the [TRPO article](https://arxiv.org/abs/1502.05477) in section 5.2.\n",
        "\n",
        "The goal here is to implement such rollout policy (we recommend using tree data structure like in the seminar above).\n",
        "Then you can assign cummulative rewards similar to `get_cummulative_rewards`, but for a tree.\n",
        "\n",
        "__bonus task__ - parallelize samples using multiple cores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJsr6IU_76h"
      },
      "source": [
        "# Homework option II (10+pts)\n",
        "\n",
        "Let's use TRPO to train evil robots! (pick any of two)\n",
        "* [MuJoCo robots](https://gym.openai.com/envs#mujoco)\n",
        "* [Box2d robot](https://gym.openai.com/envs/BipedalWalker-v2)\n",
        "\n",
        "The catch here is that those environments have continuous action spaces. \n",
        "\n",
        "Luckily, TRPO is a policy gradient method, so it's gonna work for any parametric $\\pi_\\theta(a|s)$. We recommend starting with gaussian policy:\n",
        "\n",
        "$$\\pi_\\theta(a|s) = N(\\mu_\\theta(s),\\sigma^2_\\theta(s)) = {1 \\over \\sqrt { 2 \\pi {\\sigma}_{\\theta(s)}^{2} } } e^{ (a - \n",
        "\\mu_\\theta(s))^2 \\over 2 {\\sigma}_{\\theta(s)}^{2} } $$\n",
        "\n",
        "In the $\\sqrt { 2 \\pi {\\sigma}_{\\theta(s)}^{2} }$ clause, $\\pi$ means ~3.1415926, not agent's policy.\n",
        "\n",
        "This essentially means that you will need two output layers:\n",
        "* $\\mu_\\theta(s)$, a dense layer with linear activation\n",
        "* ${\\sigma^2}_\\theta(s)$, a dense layer with activation tf.exp (to make it positive; like rho from bandits)\n",
        "\n",
        "For multidimensional actions, you can use fully factorized gaussian (basically a vector of gaussians). Namely,\n",
        "\n",
        "The Multivariate Gaussian distribution has a pdf that reads \n",
        "$$p(x\\ |\\ \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\det(\\Sigma)^{1/2}}\\exp\\left\\{ -\\frac{1}{2}\\left(x-\\mu\\right)^{T}\\Sigma^{-1}\\left(x-\\mu\\right)\\right\\}$$\n",
        "_\n",
        "\n",
        "In the case when the covariance matrix is diagonal $\\Sigma=\\mathrm{diag}(\\sigma_{1}^{2},\\dots,\\sigma_{k}^{2})$, the pdf simplifies to \n",
        "$$p(x\\ |\\ \\mu,\\sigma)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\prod_{i=1}^{k}\\sigma_{i}}\\exp\\left\\{ -\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{x_{i}-\\mu_{i}}{\\sigma_{i}}\\right)^{2}\\right\\}$$\n",
        "_\n",
        "\n",
        "Assuming $\\mu_{\\theta}:S\\rightarrow\\mathbb{R}^{k}$\n",
        "and $\\sigma_{\\theta}:S\\rightarrow\\mathbb{R}^{k}$ are functions parameterized by $\\theta$, we obtain a model-based policy of the form:\n",
        "$$\\pi_{\\theta}(a|s)=\\mathcal{N}\\left(\\mu_{\\theta}(s),\\sigma_{\\theta}^{2}(s)\\right)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\prod_{i=1}^{k}[\\sigma_{\\theta}(s)]_{i}}\\exp\\left\\{ -\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[a]_{i}-[\\mu_{\\theta}(s)]_{i}}{[\\sigma_{\\theta}(s)]_{i}}\\right)^{2}\\right\\}.$$\n",
        "_\n",
        "\n",
        "Notice that\n",
        "$$\\ln\\pi_{\\theta}(a|s)=-\\frac{k}{2}\\ln(2\\pi)-\\sum_{i=1}^{k}\\ln[\\sigma_{\\theta}(s)]_{i}-\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[a]_{i}-[\\mu_{\\theta}(s)]_{i}}{[\\sigma_{\\theta}(s)]_{i}}\\right)^{2}$$\n",
        " \n",
        "\n",
        "\n",
        "For multivariate Guassian distributions, we have\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "KL\\left(\\pi_{t}(\\cdot|s)\\:||\\:\\pi_{t+1}(\\cdot|s)\\right)&=&\\frac{1}{2}\\left\\{ -k+Tr\\left[\\Sigma_{t+1}^{-1}\\Sigma_{t}\\right]+(\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})+\\ln\\frac{\\det(\\Sigma_{t+1})}{\\det(\\Sigma_{t})}\\right\\} \\\\(\\Sigma_{t+1}=\\Sigma_{t})&=&\\frac{1}{2}\\left\\{ (\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})\\right\\} \\\\&=&\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[\\mu_{t+1}-\\mu_{t}]_{i}}{[\\sigma_{t+1}]_{i}}\\right)^{2}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "\n",
        "__bonus task__: compare performance of continuous action space method to action space discretization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmMETkn13ERp"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def normal(s, mu, sigma_sq):\n",
        "    a = np.exp( - np.square(s - mu) / (2 * sigma_sq) )\n",
        "    b = 1 / np.sqrt(2 * sigma_sq * np.pi)\n",
        "    return a*b\n",
        "\n",
        "mu = 0\n",
        "sigma = 0.1\n",
        "sigma_sq = np.square(sigma)\n",
        "\n",
        "x = normal(mu, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "# pdf\n",
        "pdf = [normal(mu + i/1000, mu, sigma_sq) for i in range(-100,100)]\n",
        "plt.plot(pdf)\n",
        "plt.show()\n",
        "\n",
        "# histogram of samples\n",
        "samples = mu + sigma * np.random.randn(10000)\n",
        "hist = plt.hist(samples, 100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDtAOru4E4FO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPg-zzzQV883"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "\n",
        "dim_action = 2\n",
        "\n",
        "@tf.function\n",
        "def tf_normal(s, mu, sigma_sq):\n",
        "    exp_term   = tf.math.exp( - tf.reduce_sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = tf.math.sqrt( tf.math.pow(2 * np.pi, dim_action) * tf.reduce_prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "s        = 0.9 * tf.ones( (2,3,dim_action), dtype = tf.float32 )\n",
        "mu       = tf.ones( (2,3,dim_action), dtype = tf.float32 )\n",
        "sigma_sq = (0.1)**2 * tf.ones((2,3,dim_action), dtype = tf.float32)\n",
        "\n",
        "\n",
        "x = tf_normal(s, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "y = multivariate_normal.pdf( s[0,0], mu[0,0], sigma_sq[0,0] )\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWUHEZE4dZtt"
      },
      "source": [
        "def normal(s, mu, sigma_sq):\n",
        "    exp_term   = np.exp( - np.sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = np.sqrt( np.pow(2 * np.pi, dim_action) * np.prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "s        = 0.9 * np.ones( (2,3,dim_action), dtype = np.float32 )\n",
        "mu       = np.ones( (2,3,dim_action), dtype = np.float32 )\n",
        "sigma_sq = (0.1)**2 * np.ones((2,3,dim_action), dtype = np.float32)\n",
        "\n",
        "\n",
        "x = tf_normal(s, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "y = multivariate_normal.pdf( s[0,0], mu[0,0], sigma_sq[0,0] )\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_YHQlGWd2Rb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}