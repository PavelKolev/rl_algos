{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO_GAE_LLCont_sigma_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1VqP1NKsPe",
        "outputId": "7b4c9ebe-7db0-4a7f-b1c6-ac6db1a80566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep 30 09:06:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG0sRYAbKtja",
        "outputId": "c68f0030-df9a-4613-82a7-aafc10991e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXEex1K2K0Se"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SRyzt5S_75J",
        "outputId": "6e7a109a-a51a-4881-e188-664ab73f34f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://github.com/yandexdataschool/Practical_RL/issues/256\n",
        "    !pip uninstall tensorflow --yes\n",
        "    !pip uninstall keras --yes\n",
        "    !pip install tensorflow-gpu==1.13.1\n",
        "    !pip install keras==2.2.4\n",
        "    \n",
        "    if not os.path.exists('.setup_complete'):\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "        !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "!pip install box2d-py\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "Uninstalling Keras-2.4.3:\n",
            "  Successfully uninstalled Keras-2.4.3\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 58.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (50.3.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.0)\n",
            "Installing collected packages: mock, tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.4\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 144619 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.6_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n",
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQAUCblQ_75N"
      },
      "source": [
        "### Let's make a TRPO!\n",
        "\n",
        "In this notebook we will write the code of the one Trust Region Policy Optimization.\n",
        "As usually, it contains a few different parts which we are going to reproduce.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzsdr5_8_75O"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import gym\n",
        "import numpy as np\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzq9yG7_75R",
        "outputId": "c97294c2-1e9c-43ad-9c56-beccb28b8563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "env.reset()\n",
        "\n",
        "dim_state = env.observation_space.shape[0]\n",
        "print(\"Size of State Space ->  {}\".format(dim_state))\n",
        "\n",
        "dim_action = env.action_space.shape[0]\n",
        "print(\"Size of Action Space ->  {}\".format(dim_action))\n",
        "\n",
        "lower_bound = env.action_space.low[0]\n",
        "upper_bound = env.action_space.high[0]\n",
        "\n",
        "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
        "print(\"Max Value of Action ->  {}\".format(upper_bound))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of State Space ->  8\n",
            "Size of Action Space ->  2\n",
            "Min Value of Action ->  -1.0\n",
            "Max Value of Action ->  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AS5Om-4_75T",
        "outputId": "4a9caa5b-879a-4328-9d44-1a2caa607c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(env.render('rgb_array'))\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgvVN9_z_75W"
      },
      "source": [
        "### Step 1: Defining a network\n",
        "\n",
        "With all it's complexity, at it's core TRPO is yet another policy gradient method. \n",
        "\n",
        "This essentially means we're actually training a stochastic policy $ \\pi_\\theta(a|s) $. \n",
        "\n",
        "And yes, it's gonna be a neural network. So let's start by defining one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0sJTpTj_75X"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Unknown Time dimention = None\n",
        "\n",
        "# input tensors\n",
        "obs_ph  = tf.placeholder(shape=(None, dim_state), dtype=tf.float32)\n",
        "\n",
        "# \n",
        "p_beta_ph = tf.placeholder(shape=(), dtype=tf.float32)\n",
        "v_beta_ph = tf.placeholder(shape=(), dtype=tf.float32)\n",
        "\n",
        "# Actions that we made\n",
        "actions_ph   = tf.placeholder(shape=(None, dim_action), dtype=tf.float32)\n",
        "\n",
        "# Previous Model \"mu\" prediction\n",
        "old_mu_ph    = tf.placeholder(shape=(None, dim_action), dtype=tf.float32)\n",
        "old_V_ph     = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Action probabilities from previous iteration\n",
        "old_probs_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# GAE\n",
        "advantage_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Cumulative Return \"G = r + gamma*r' + gamma^2*r'' + ...\"\n",
        "c_returns_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Sigma is an input parameter!\n",
        "sigma_sq = (2 ** 2) * tf.ones((dim_action, ), dtype=tf.float32)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IVhWlCeCj3"
      },
      "source": [
        "Multivariate Gaussian PDF: \n",
        "\n",
        "TF and np functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmzQntJ_I-gN"
      },
      "source": [
        "def tf_normal(s, mu, sigma_sq):\n",
        "    exp_term   = tf.math.exp( - tf.reduce_sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = tf.math.sqrt( tf.math.pow(2 * np.pi, dim_action) * tf.reduce_prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "def normal(s, mu, sigma_sq):\n",
        "    exp_term   = np.exp( - np.sum( np.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = np.sqrt( np.pow(2 * np.pi, dim_action) * np.prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "def sample_action(mu, sigma_sq):\n",
        "    action = mu + np.sqrt(sigma_sq) * np.random.randn( mu.shape[0] )\n",
        "    return action\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOPs8OEn_75a",
        "outputId": "05713744-634a-4685-a67b-c64ab1757062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def denselayer(name, x, out_dim, nonlinearity=None):\n",
        "    with tf.variable_scope(name):\n",
        "        if nonlinearity is None:\n",
        "            nonlinearity = tf.identity\n",
        "\n",
        "        W = tf.get_variable('W', shape=[x.shape[1], out_dim])\n",
        "        b = tf.get_variable('b', shape=[out_dim], \n",
        "                            initializer = tf.compat.v1.random_normal_initializer(mean=0.0, stddev=0.05))\n",
        "        o = nonlinearity(tf.matmul(x, W) + b)\n",
        "        return o\n",
        "\n",
        "\n",
        "# Interactive Session\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# NN for prediction of mu\n",
        "nn = denselayer(\"policy_layer_1\", obs_ph, 64, tf.nn.tanh)\n",
        "nn = denselayer(\"policy_layer_2\", nn, 64, tf.nn.tanh)\n",
        "nn = denselayer(\"policy_layer_3\", nn, 64, tf.nn.tanh)\n",
        "mu = denselayer(\"policy\", nn, dim_action, tf.nn.tanh)\n",
        "\n",
        "# Actions\n",
        "probs_ph = tf_normal(actions_ph, mu, sigma_sq)\n",
        "\n",
        "# NN for prediction of V\n",
        "nn  = denselayer(\"value_layer_1\", obs_ph, 64, tf.nn.relu)\n",
        "nn  = denselayer(\"value_layer_2\", nn, 64, tf.nn.relu)\n",
        "nn  = denselayer(\"value_layer_3\", nn, 64, tf.nn.relu)\n",
        "V   = denselayer(\"value\", nn, 1, None)\n",
        "\n",
        "# Get Trainable Variables\n",
        "train_vars = tf.trainable_variables()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auf2Au2__758"
      },
      "source": [
        "### Step 3: loss functions\n",
        "\n",
        "Now let's define the loss functions and constraints for actual TRPO training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EkGpySi_759"
      },
      "source": [
        "Advantage:\n",
        "$$A_{\\theta_{old}}(s_{i},a_{i})=G_{\\theta_{old}}(s_{i},a_{i})-V_{\\theta_{old}}(s_{i})$$\n",
        "\n",
        "where the gain function is\n",
        "$$G_{\\theta_{old}}(s_{i},a_{i})=\\sum_{j=i}^{T}\\gamma^{j-i}r_{j}$$\n",
        "\n",
        "The surrogate reward should be\n",
        "$$J_{surr}= {1 \\over N} \\sum\\limits_{i=0}^N \\frac{\\pi_{\\theta}(s_i, a_i)}{\\pi_{\\theta_{old}}(s_i, a_i)}\n",
        "A_{\\theta_{old}}(s_{i},a_{i})$$\n",
        "\n",
        "Clip Loss Function\n",
        "$$L_{\\theta_{old}}^{CLIP}(\\theta)=\\frac{1}{N}\\sum\\limits _{i=0}^{N}\\min\\left\\{ \\frac{\\pi_{\\theta}(s_{i},a_{i})}{\\pi_{\\theta_{old}}(s_{i},a_{i})}A_{\\theta_{old}}(s_{i},a_{i}),\\ g\\left(\\epsilon,A_{\\theta_{old}}(s_{i},a_{i})\\right)\\right\\}$$\n",
        "\n",
        "where function\n",
        "$$g(\\epsilon,A)=\\begin{cases}\n",
        "(1+\\epsilon)A & ,\\text{ if }A\\geq0\\\\\n",
        "(1-\\epsilon)A & ,\\text{ o.w.}\n",
        "\\end{cases}$$\n",
        "\n",
        "Or alternatively, minimize the surrogate loss:\n",
        "$$ L_{surr} = - L_{\\theta_{old}}^{CLIP}(\\theta) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGzd6WwT_76B"
      },
      "source": [
        "# Compute surrogate loss: negative importance-sampled policy gradient\n",
        "batch_size = tf.cast(tf.shape(mu)[0], tf.float32)\n",
        "\n",
        "# select probabilities of chosen actions\n",
        "probs_all     = tf.reshape(probs_ph, [-1])\n",
        "old_probs_all = tf.reshape(old_probs_ph, [-1])\n",
        "ratio_ph      = probs_all / old_probs_all\n",
        "\n",
        "# clipping pattern\n",
        "epsilon = 0.2\n",
        "clippling_pattern = tf.minimum((1 - epsilon) * advantage_ph, 0) +\\\n",
        "                    tf.maximum((1 + epsilon) * advantage_ph, 0)\n",
        "\n",
        "# Clipped Loss\n",
        "L_surr = tf.reduce_mean( tf.minimum(ratio_ph * advantage_ph, clippling_pattern) )\n",
        "\n",
        "\n",
        "# Value loss\n",
        "V_objective = tf.reduce_mean( tf.math.square( V[:,0] - c_returns_ph ) )\n",
        "\n",
        "ss_sq    = tf.reduce_mean( tf.math.square( old_V_ph - c_returns_ph ) )\n",
        "kl_value = tf.reduce_mean( tf.math.square( V[:0] - old_V_ph ) ) / (2 * ss_sq)\n",
        "\n",
        "V_loss = V_objective + v_beta_ph * kl_value\n",
        "train_V_loss = tf.train.AdamOptimizer(1e-4).minimize(V_loss)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imv9XYia_76F"
      },
      "source": [
        "We can ascend these gradients as long as our $\\pi_\\theta(a|s)$ satisfies the constraint\n",
        "$$E_{s,\\pi_{\\Theta_{t}}}\\Big[KL(\\pi(\\Theta_{t}, s) \\:||\\:\\pi(\\Theta_{t+1}, s))\\Big] < \\alpha$$\n",
        "\n",
        "\n",
        "\n",
        "For multivariate Guassian distributions, we have\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "KL\\left(\\pi_{t}(\\cdot|s)\\:||\\:\\pi_{t+1}(\\cdot|s)\\right)&=&\\frac{1}{2}\\left\\{ -k+Tr\\left[\\Sigma_{t+1}^{-1}\\Sigma_{t}\\right]+(\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})+\\ln\\frac{\\det(\\Sigma_{t+1})}{\\det(\\Sigma_{t})}\\right\\} \\\\(\\Sigma_{t+1}=\\Sigma_{t})&=&\\frac{1}{2}\\left\\{ (\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})\\right\\} \\\\&=&\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[\\mu_{t+1}-\\mu_{t}]_{i}}{[\\sigma_{t+1}]_{i}}\\right)^{2}\n",
        "\\end{eqnarray*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvAuUZZU_76G",
        "outputId": "b03f082b-925c-4def-a39e-bd17bc2c92e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Compute Kullback-Leibler divergence (see formula above)\n",
        "# Note: you need to sum KL and entropy over all actions, not just the ones agent took\n",
        "\n",
        "kl_policy = 0.5 * tf.reduce_sum( tf.math.square(mu - old_mu_ph) / (2 * sigma_sq))\n",
        "kl_policy /= batch_size\n",
        "\n",
        "# Compute policy entropy\n",
        "log_probs_all = tf.math.log(probs_all + 1e-5)\n",
        "entropy       = - tf.reduce_sum(probs_all * log_probs_all) / batch_size\n",
        "\n",
        "# Goal is to maximize: L_surr, minimize beta_ph * kl, maximize entropy\n",
        "# Since we use minimizer, we have\n",
        "policy_loss       = -L_surr + p_beta_ph * kl_policy - entropy\n",
        "train_Policy_loss = tf.train.AdamOptimizer(1e-4).minimize(policy_loss)\n",
        "\n",
        "# No variable depends on the following losses\n",
        "# Used only for progress tracking\n",
        "#losses = [L_surr, kl_policy, entropy, kl_value]\n",
        "losses = [kl_policy, kl_value]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BePcHv1K-u5"
      },
      "source": [
        "# Initialize TF\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjOp0ljT34VM"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt64G5Pi3xfO",
        "outputId": "63dbe721-69c0-4f49-878f-f07cfa0b64df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Restore variables from disk.\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, \"model.ckpt\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_rSvyFq355u"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljE2-68L_75f"
      },
      "source": [
        "### Step 2: Actions and rollouts\n",
        "\n",
        "In this section, we'll define functions that take actions $ a \\sim \\pi_\\theta(a|s) $ and rollouts $ \\langle s_0,a_0,s_1,a_1,s_2,a_2,...s_n,a_n \\rangle $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TaUC34w_75f"
      },
      "source": [
        "def act(obs, sample = True):\n",
        "    \"\"\"\n",
        "    Samples action from policy distribution (sample = True) or takes most likely action (sample = False)\n",
        "    :param: obs - single observation vector\n",
        "    :param sample: if True, samples from \\pi, otherwise takes most likely action\n",
        "    :returns: mu, V, action, prob\n",
        "    \"\"\"\n",
        "    # obs.reshape((1, -1)) makes batch first: [[obs]]\n",
        "    feed_dict = {obs_ph: obs.reshape((1, -1))}\n",
        "    mu_eval, V_eval   = sess.run([mu, V], feed_dict = feed_dict)\n",
        "    mu_eval = mu_eval[0]\n",
        "    V_eval  = V_eval[0,0]\n",
        "\n",
        "    # Sample action\n",
        "    action = sample_action(mu_eval, sigma_sq.eval()) if sample == True else mu_eval\n",
        "\n",
        "    # Add actions to the dictionary\n",
        "    feed_dict[actions_ph] = action[None]\n",
        "    prob = sess.run(probs_ph, feed_dict = feed_dict)[0]\n",
        "\n",
        "    return mu_eval, V_eval, action, prob"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX7Wf5kj_75o"
      },
      "source": [
        "Compute cummulative reward just like you did in vanilla REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDLeSmTX_75w"
      },
      "source": [
        "**Rollout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbJKrqLFCsNy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_GAE(r, v, v_p, gamma=1, gae_param=1):\n",
        "    n   = np.shape(r)[0]\n",
        "    gae = np.zeros(n, dtype=np.float32)\n",
        "\n",
        "    d = np.zeros(n, dtype = np.float32)\n",
        "    d[:-1] = r[:-1] + gamma * v[1:] - v[:-1]\n",
        "    d[-1]  = r[-1]  + gamma * v_p   - v[-1]\n",
        "    \n",
        "    gae[n-1] = d[n-1]\n",
        "    for i in reversed(range(n-1)):\n",
        "        gae[i] = d[i] + ( gae_param * gamma ) * gae[i+1]\n",
        "\n",
        "    return gae"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UFon-4g_75x"
      },
      "source": [
        "# A valid path in a rollout must either:\n",
        "# end up in a \"done\" state or\n",
        "# exceed the allowed steps\n",
        "# NOTE: We might end up with a single path that exceeds steps limit !\n",
        "\n",
        "def rollout(env, act, gamma=1, gae_param=1, max_pathlength=3000, n_timesteps=10000):\n",
        "    \"\"\"\n",
        "    Generate rollouts for training.\n",
        "    :param: env - environment in which we will make actions to generate rollouts.\n",
        "    :param: act - the function that can return policy and action given observation.\n",
        "    :param: max_pathlength - maximum size of one path that we generate.\n",
        "    :param: n_timesteps - total sum of sizes of all pathes we generate.\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "\n",
        "    total_timesteps = 0\n",
        "\n",
        "    while total_timesteps < n_timesteps:\n",
        "        obervations, mu_evals, V_evals, actions, rewards, action_probs = [], [], [], [], [], []\n",
        "        obervation = env.reset()\n",
        "        \n",
        "        for _ in range(max_pathlength):\n",
        "            mu_eval, V_eval, action, action_prob = act(obervation)\n",
        "\n",
        "            obervations.append(obervation)\n",
        "            mu_evals.append(mu_eval)\n",
        "            V_evals.append(V_eval)\n",
        "            actions.append(action)\n",
        "            action_probs.append(action_prob)\n",
        "\n",
        "            obervation, reward, done, _ = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            total_timesteps += 1\n",
        "\n",
        "            if done or total_timesteps == n_timesteps:\n",
        "                v_p = 0 if done else act(obervation)[1]\n",
        "                \n",
        "                np_values  = np.array(V_evals)\n",
        "                np_rewards = np.array(rewards)\n",
        "                \n",
        "                np_gae = get_GAE(np_rewards, np_values, v_p, gamma, gae_param)\n",
        "                cummulative_rewards = np_values + np_gae\n",
        "\n",
        "                path = {\"observations\": np.array(obervations),\n",
        "                        \"mu_evals\": np.array(mu_evals),\n",
        "                        \"values\": np_values,\n",
        "                        \"actions\": np.array(actions),\n",
        "                        \"action_probs\":  np.array(action_probs),\n",
        "                        \"cumulative_returns\": cummulative_rewards,\n",
        "                        \"GAE\": np_gae,\n",
        "                        \"reward\": np.sum(np_rewards),\n",
        "                        }\n",
        "                paths.append(path)\n",
        "                break\n",
        "    # outputs List of Dictionaries (feed to nn)\n",
        "    return paths"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrH9E9sk_76c"
      },
      "source": [
        "##### Step 5: Main PPO loop\n",
        "\n",
        "Here we will train our network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiROykhhcUp-"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import trange\n",
        "import pickle\n",
        "\n",
        "eps = 0.01\n",
        "\n",
        "gamma     = 0.99\n",
        "gae_param = 0.95\n",
        "\n",
        "p_beta = 100\n",
        "v_beta = 100\n",
        "\n",
        "# Number of Gradient descent iterations for policy\n",
        "grad_iters = 5\n",
        "\n",
        "# To store average reward history of last few episodes\n",
        "avg_reward_list = []\n",
        "std_reward_list = []\n",
        "\n",
        "#Load \n",
        "with open(\"avg_reward_list.txt\", \"rb\") as fp:   # Unpickling\n",
        "    avg_reward_list = pickle.load(fp)\n",
        "\n",
        "with open(\"std_reward_list.txt\", \"rb\") as fp:   # Unpickling\n",
        "    std_reward_list = pickle.load(fp)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgJmJFz1_76d",
        "outputId": "264b50da-a086-4bae-a26c-be58f6e5dfae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "#import time\n",
        "#from itertools import count\n",
        "#from collections import OrderedDict\n",
        "#num_epis_total = 0    # number of played episodes\n",
        "#start_time = time.time()\n",
        "\n",
        "done_iters = 400\n",
        "iters = 100\n",
        "x_axis = list(range(1,len(avg_reward_list)+1))\n",
        "\n",
        "for i in trange(iters):\n",
        "\n",
        "    # Generating paths.\n",
        "    paths = rollout(env, act, gamma, gae_param)\n",
        "    \n",
        "    # Load feed_dict and old_weights\n",
        "    observations = np.concatenate([path[\"observations\"] for path in paths])\n",
        "    old_mu_eval  = np.concatenate([path[\"mu_evals\"] for path in paths])\n",
        "    old_V_eval   = np.concatenate([path[\"values\"] for path in paths])\n",
        "    actions      = np.concatenate([path[\"actions\"] for path in paths])\n",
        "    old_probs    = np.concatenate([path[\"action_probs\"] for path in paths])\n",
        "    c_returns    = np.concatenate([path[\"cumulative_returns\"] for path in paths])\n",
        "    GAE          = np.concatenate([path[\"GAE\"] for path in paths])\n",
        "    \n",
        "    feed_dict_policy = {obs_ph: observations,\n",
        "                        old_mu_ph: old_mu_eval,\n",
        "                        actions_ph: actions,\n",
        "                        old_probs_ph: old_probs,\n",
        "                        advantage_ph: GAE,\n",
        "                        c_returns_ph: c_returns,\n",
        "                        p_beta_ph: p_beta,}\n",
        "\n",
        "    for _ in range(grad_iters):\n",
        "        # Train Policy loss\n",
        "        sess.run(train_Policy_loss, feed_dict = feed_dict_policy)\n",
        "\n",
        "    feed_dict_value = {obs_ph: observations,\n",
        "                       c_returns_ph: c_returns,\n",
        "                       old_V_ph: old_V_eval,\n",
        "                       v_beta_ph: v_beta}\n",
        "\n",
        "    for _ in range(grad_iters):\n",
        "        # Train State Value loss\n",
        "        sess.run(train_V_loss, feed_dict = feed_dict_value)\n",
        "    \n",
        "    feed_dict_loss = feed_dict_policy\n",
        "    for k in feed_dict_value.keys():\n",
        "        feed_dict_loss[k] = feed_dict_value[k]\n",
        "\n",
        "    # Report current progress\n",
        "    kl_policy_v, kl_value_v = sess.run(losses, feed_dict = feed_dict_loss)\n",
        "    \n",
        "    # Update soft constraint regulizers\n",
        "    if kl_policy_v >= 1.5 * eps:\n",
        "        p_beta *= 2\n",
        "    if kl_policy_v <= eps / 1.5:\n",
        "        p_beta /= 2\n",
        "\n",
        "    if kl_value_v >= 1.5 * eps:\n",
        "        v_beta *= 2\n",
        "    if kl_value_v <= eps / 1.5:\n",
        "        v_beta /= 2\n",
        "    \n",
        "    episode_rewards = np.array([path[\"reward\"] for path in paths])\n",
        "    \n",
        "    avg_reward_list.append(episode_rewards.mean())\n",
        "    std_reward_list.append(episode_rewards.std())\n",
        "\n",
        "    #Print Figure\n",
        "    x_axis.append(done_iters + i + 1)\n",
        "\n",
        "    clear_output(True)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle('Mean and Std Reward')\n",
        "    ax1.plot(x_axis, avg_reward_list)\n",
        "    ax2.plot(x_axis, std_reward_list)\n",
        "    ax1.set(xlabel='Episode', ylabel='Mean Reward')\n",
        "    ax2.set(xlabel='Episode', ylabel='Std Reward')\n",
        "    fig.tight_layout(pad=3.0)\n",
        "    plt.show()\n",
        "\n",
        "    #stats = OrderedDict()\n",
        "    #num_epis_total += len(episode_rewards)\n",
        "\n",
        "    #stats[\"Total number of episodes\"] = num_epis_total\n",
        "    #stats[\"Average sum of rewards per episode\"] = episode_rewards.mean()\n",
        "    #stats[\"Std of rewards per episode\"] = episode_rewards.std()\n",
        "    #stats[\"Entropy\"] = entropy\n",
        "    #stats[\"Time elapsed\"] = \"%.2f mins\" % ((time.time() - start_time)/60.)\n",
        "    #stats[\"KL between old and new distribution\"] = kl\n",
        "    #stats[\"Surrogate loss\"] = L_surr\n",
        "\n",
        "    #for k, v in stats.items():\n",
        "    #    print(k + \": \" + \" \" * (40 - len(k)) + str(v))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [1:08:35<00:00, 41.15s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYNm-Ga_q36w"
      },
      "source": [
        "# Save to disk\n",
        "saver = tf.train.Saver()\n",
        "saver.save(sess, \"model.ckpt\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(\"avg_reward_list.txt\", \"wb\") as fp:\n",
        "    pickle.dump(avg_reward_list, fp)\n",
        "\n",
        "with open(\"std_reward_list.txt\", \"wb\") as fp:\n",
        "    pickle.dump(std_reward_list, fp)    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_T5qDKCx17K",
        "outputId": "bc04e3d4-ebcc-4ae8-e039-e38d34b6ea44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "paths = rollout(env, act)\n",
        "print(np.mean([path['reward'] for path in paths]))\n",
        "\n",
        "x = [path['reward'] for path in paths]\n",
        "plt.hist(x, bins = 50)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-31.847312468490106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEBoGP13IoC8"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KXLiWZYben0"
      },
      "source": [
        "def evaluate(env, n_games=1):\n",
        "    \"\"\"Plays an a game from start till done, returns per-game rewards \"\"\"\n",
        "\n",
        "    game_rewards = []\n",
        "    for _ in range(n_games):\n",
        "        # initial observation and memory\n",
        "        observation = env.reset()\n",
        "\n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            mu_eval, V_eval, action, prob = act(observation)\n",
        "            observation, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        game_rewards.append(total_reward)\n",
        "    return game_rewards"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6bjqpBtl9_c",
        "outputId": "7367024b-faa8-4f55-df85-ec7429374ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gym.wrappers\n",
        "\n",
        "with gym.wrappers.Monitor(env, directory=\"videos\", force=True) as env_monitor:\n",
        "    final_rewards = evaluate(env_monitor, n_games=5)\n",
        "\n",
        "print(\"Final rewards\", np.mean(final_rewards))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final rewards 20.625324131452764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IXb-scZdj2I"
      },
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(video_names[-1]))  # You can also try other indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6mISEoL_76h"
      },
      "source": [
        "# Homework option I: better sampling (10+pts)\n",
        "\n",
        "In this section, you're invited to implement a better rollout strategy called _vine_.\n",
        "\n",
        "![img](https://s17.postimg.cc/i90chxgvj/vine.png)\n",
        "\n",
        "In most gym environments, you can actually backtrack by using states. You can find a wrapper that saves/loads states in [the mcts seminar](https://github.com/yandexdataschool/Practical_RL/blob/master/week10_planning/seminar_MCTS.ipynb).\n",
        "\n",
        "You can read more about in the [TRPO article](https://arxiv.org/abs/1502.05477) in section 5.2.\n",
        "\n",
        "The goal here is to implement such rollout policy (we recommend using tree data structure like in the seminar above).\n",
        "Then you can assign cummulative rewards similar to `get_cummulative_rewards`, but for a tree.\n",
        "\n",
        "__bonus task__ - parallelize samples using multiple cores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJsr6IU_76h"
      },
      "source": [
        "# Homework option II (10+pts)\n",
        "\n",
        "Let's use TRPO to train evil robots! (pick any of two)\n",
        "* [MuJoCo robots](https://gym.openai.com/envs#mujoco)\n",
        "* [Box2d robot](https://gym.openai.com/envs/BipedalWalker-v2)\n",
        "\n",
        "The catch here is that those environments have continuous action spaces. \n",
        "\n",
        "Luckily, TRPO is a policy gradient method, so it's gonna work for any parametric $\\pi_\\theta(a|s)$. We recommend starting with gaussian policy:\n",
        "\n",
        "$$\\pi_\\theta(a|s) = N(\\mu_\\theta(s),\\sigma^2_\\theta(s)) = {1 \\over \\sqrt { 2 \\pi {\\sigma}_{\\theta(s)}^{2} } } e^{ (a - \n",
        "\\mu_\\theta(s))^2 \\over 2 {\\sigma}_{\\theta(s)}^{2} } $$\n",
        "\n",
        "In the $\\sqrt { 2 \\pi {\\sigma}_{\\theta(s)}^{2} }$ clause, $\\pi$ means ~3.1415926, not agent's policy.\n",
        "\n",
        "This essentially means that you will need two output layers:\n",
        "* $\\mu_\\theta(s)$, a dense layer with linear activation\n",
        "* ${\\sigma^2}_\\theta(s)$, a dense layer with activation tf.exp (to make it positive; like rho from bandits)\n",
        "\n",
        "For multidimensional actions, you can use fully factorized gaussian (basically a vector of gaussians). Namely,\n",
        "\n",
        "The Multivariate Gaussian distribution has a pdf that reads \n",
        "$$p(x\\ |\\ \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\det(\\Sigma)^{1/2}}\\exp\\left\\{ -\\frac{1}{2}\\left(x-\\mu\\right)^{T}\\Sigma^{-1}\\left(x-\\mu\\right)\\right\\}$$\n",
        "_\n",
        "\n",
        "In the case when the covariance matrix is diagonal $\\Sigma=\\mathrm{diag}(\\sigma_{1}^{2},\\dots,\\sigma_{k}^{2})$, the pdf simplifies to \n",
        "$$p(x\\ |\\ \\mu,\\sigma)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\prod_{i=1}^{k}\\sigma_{i}}\\exp\\left\\{ -\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{x_{i}-\\mu_{i}}{\\sigma_{i}}\\right)^{2}\\right\\}$$\n",
        "_\n",
        "\n",
        "Assuming $\\mu_{\\theta}:S\\rightarrow\\mathbb{R}^{k}$\n",
        "and $\\sigma_{\\theta}:S\\rightarrow\\mathbb{R}^{k}$ are functions parameterized by $\\theta$, we obtain a model-based policy of the form:\n",
        "$$\\pi_{\\theta}(a|s)=\\mathcal{N}\\left(\\mu_{\\theta}(s),\\sigma_{\\theta}^{2}(s)\\right)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\prod_{i=1}^{k}[\\sigma_{\\theta}(s)]_{i}}\\exp\\left\\{ -\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[a]_{i}-[\\mu_{\\theta}(s)]_{i}}{[\\sigma_{\\theta}(s)]_{i}}\\right)^{2}\\right\\}.$$\n",
        "_\n",
        "\n",
        "Notice that\n",
        "$$\\ln\\pi_{\\theta}(a|s)=-\\frac{k}{2}\\ln(2\\pi)-\\sum_{i=1}^{k}\\ln[\\sigma_{\\theta}(s)]_{i}-\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[a]_{i}-[\\mu_{\\theta}(s)]_{i}}{[\\sigma_{\\theta}(s)]_{i}}\\right)^{2}$$\n",
        " \n",
        "\n",
        "\n",
        "For multivariate Guassian distributions, we have\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "KL\\left(\\pi_{t}(\\cdot|s)\\:||\\:\\pi_{t+1}(\\cdot|s)\\right)&=&\\frac{1}{2}\\left\\{ -k+Tr\\left[\\Sigma_{t+1}^{-1}\\Sigma_{t}\\right]+(\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})+\\ln\\frac{\\det(\\Sigma_{t+1})}{\\det(\\Sigma_{t})}\\right\\} \\\\(\\Sigma_{t+1}=\\Sigma_{t})&=&\\frac{1}{2}\\left\\{ (\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})\\right\\} \\\\&=&\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[\\mu_{t+1}-\\mu_{t}]_{i}}{[\\sigma_{t+1}]_{i}}\\right)^{2}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "\n",
        "__bonus task__: compare performance of continuous action space method to action space discretization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmMETkn13ERp"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def normal(s, mu, sigma_sq):\n",
        "    a = np.exp( - np.square(s - mu) / (2 * sigma_sq) )\n",
        "    b = 1 / np.sqrt(2 * sigma_sq * np.pi)\n",
        "    return a*b\n",
        "\n",
        "mu = 0\n",
        "sigma = 0.1\n",
        "sigma_sq = np.square(sigma)\n",
        "\n",
        "x = normal(mu, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "# pdf\n",
        "pdf = [normal(mu + i/1000, mu, sigma_sq) for i in range(-100,100)]\n",
        "plt.plot(pdf)\n",
        "plt.show()\n",
        "\n",
        "# histogram of samples\n",
        "samples = mu + sigma * np.random.randn(10000)\n",
        "hist = plt.hist(samples, 100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDtAOru4E4FO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPg-zzzQV883"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "\n",
        "dim_action = 2\n",
        "\n",
        "@tf.function\n",
        "def tf_normal(s, mu, sigma_sq):\n",
        "    exp_term   = tf.math.exp( - tf.reduce_sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = tf.math.sqrt( tf.math.pow(2 * np.pi, dim_action) * tf.reduce_prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "s        = 0.9 * tf.ones( (2,3,dim_action), dtype = tf.float32 )\n",
        "mu       = tf.ones( (2,3,dim_action), dtype = tf.float32 )\n",
        "sigma_sq = (0.1)**2 * tf.ones((2,3,dim_action), dtype = tf.float32)\n",
        "\n",
        "\n",
        "x = tf_normal(s, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "y = multivariate_normal.pdf( s[0,0], mu[0,0], sigma_sq[0,0] )\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWUHEZE4dZtt"
      },
      "source": [
        "def normal(s, mu, sigma_sq):\n",
        "    exp_term   = np.exp( - np.sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = np.sqrt( np.pow(2 * np.pi, dim_action) * np.prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "s        = 0.9 * np.ones( (2,3,dim_action), dtype = np.float32 )\n",
        "mu       = np.ones( (2,3,dim_action), dtype = np.float32 )\n",
        "sigma_sq = (0.1)**2 * np.ones((2,3,dim_action), dtype = np.float32)\n",
        "\n",
        "\n",
        "x = tf_normal(s, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "y = multivariate_normal.pdf( s[0,0], mu[0,0], sigma_sq[0,0] )\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_YHQlGWd2Rb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}