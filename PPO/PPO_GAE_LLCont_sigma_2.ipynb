{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO_GAE_LLCont_sigma_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1VqP1NKsPe",
        "outputId": "7b4c9ebe-7db0-4a7f-b1c6-ac6db1a80566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep 30 09:06:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG0sRYAbKtja",
        "outputId": "c68f0030-df9a-4613-82a7-aafc10991e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXEex1K2K0Se"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SRyzt5S_75J",
        "outputId": "6e7a109a-a51a-4881-e188-664ab73f34f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://github.com/yandexdataschool/Practical_RL/issues/256\n",
        "    !pip uninstall tensorflow --yes\n",
        "    !pip uninstall keras --yes\n",
        "    !pip install tensorflow-gpu==1.13.1\n",
        "    !pip install keras==2.2.4\n",
        "    \n",
        "    if not os.path.exists('.setup_complete'):\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "        !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "!pip install box2d-py\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "Uninstalling Keras-2.4.3:\n",
            "  Successfully uninstalled Keras-2.4.3\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 58.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (50.3.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.0)\n",
            "Installing collected packages: mock, tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.4\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 144619 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.6_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n",
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQAUCblQ_75N"
      },
      "source": [
        "### Let's make a TRPO!\n",
        "\n",
        "In this notebook we will write the code of the one Trust Region Policy Optimization.\n",
        "As usually, it contains a few different parts which we are going to reproduce.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzsdr5_8_75O"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import gym\n",
        "import numpy as np\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzq9yG7_75R",
        "outputId": "c97294c2-1e9c-43ad-9c56-beccb28b8563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "env.reset()\n",
        "\n",
        "dim_state = env.observation_space.shape[0]\n",
        "print(\"Size of State Space ->  {}\".format(dim_state))\n",
        "\n",
        "dim_action = env.action_space.shape[0]\n",
        "print(\"Size of Action Space ->  {}\".format(dim_action))\n",
        "\n",
        "lower_bound = env.action_space.low[0]\n",
        "upper_bound = env.action_space.high[0]\n",
        "\n",
        "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
        "print(\"Max Value of Action ->  {}\".format(upper_bound))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of State Space ->  8\n",
            "Size of Action Space ->  2\n",
            "Min Value of Action ->  -1.0\n",
            "Max Value of Action ->  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AS5Om-4_75T",
        "outputId": "4a9caa5b-879a-4328-9d44-1a2caa607c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(env.render('rgb_array'))\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgvVN9_z_75W"
      },
      "source": [
        "### Step 1: Defining a network\n",
        "\n",
        "With all it's complexity, at it's core TRPO is yet another policy gradient method. \n",
        "\n",
        "This essentially means we're actually training a stochastic policy $ \\pi_\\theta(a|s) $. \n",
        "\n",
        "And yes, it's gonna be a neural network. So let's start by defining one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0sJTpTj_75X"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Unknown Time dimention = None\n",
        "\n",
        "# input tensors\n",
        "obs_ph  = tf.placeholder(shape=(None, dim_state), dtype=tf.float32)\n",
        "\n",
        "# \n",
        "p_beta_ph = tf.placeholder(shape=(), dtype=tf.float32)\n",
        "v_beta_ph = tf.placeholder(shape=(), dtype=tf.float32)\n",
        "\n",
        "# Actions that we made\n",
        "actions_ph   = tf.placeholder(shape=(None, dim_action), dtype=tf.float32)\n",
        "\n",
        "# Previous Model \"mu\" prediction\n",
        "old_mu_ph    = tf.placeholder(shape=(None, dim_action), dtype=tf.float32)\n",
        "old_V_ph     = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Action probabilities from previous iteration\n",
        "old_probs_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# GAE\n",
        "advantage_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Cumulative Return \"G = r + gamma*r' + gamma^2*r'' + ...\"\n",
        "c_returns_ph = tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
        "\n",
        "# Sigma is an input parameter!\n",
        "sigma_sq = (2 ** 2) * tf.ones((dim_action, ), dtype=tf.float32)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IVhWlCeCj3"
      },
      "source": [
        "Multivariate Gaussian PDF: \n",
        "\n",
        "TF and np functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmzQntJ_I-gN"
      },
      "source": [
        "def tf_normal(s, mu, sigma_sq):\n",
        "    exp_term   = tf.math.exp( - tf.reduce_sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = tf.math.sqrt( tf.math.pow(2 * np.pi, dim_action) * tf.reduce_prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "def normal(s, mu, sigma_sq):\n",
        "    exp_term   = np.exp( - np.sum( np.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = np.sqrt( np.pow(2 * np.pi, dim_action) * np.prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "def sample_action(mu, sigma_sq):\n",
        "    action = mu + np.sqrt(sigma_sq) * np.random.randn( mu.shape[0] )\n",
        "    return action\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOPs8OEn_75a",
        "outputId": "05713744-634a-4685-a67b-c64ab1757062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "def denselayer(name, x, out_dim, nonlinearity=None):\n",
        "    with tf.variable_scope(name):\n",
        "        if nonlinearity is None:\n",
        "            nonlinearity = tf.identity\n",
        "\n",
        "        W = tf.get_variable('W', shape=[x.shape[1], out_dim])\n",
        "        b = tf.get_variable('b', shape=[out_dim], \n",
        "                            initializer = tf.compat.v1.random_normal_initializer(mean=0.0, stddev=0.05))\n",
        "        o = nonlinearity(tf.matmul(x, W) + b)\n",
        "        return o\n",
        "\n",
        "\n",
        "# Interactive Session\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# NN for prediction of mu\n",
        "nn = denselayer(\"policy_layer_1\", obs_ph, 64, tf.nn.tanh)\n",
        "nn = denselayer(\"policy_layer_2\", nn, 64, tf.nn.tanh)\n",
        "nn = denselayer(\"policy_layer_3\", nn, 64, tf.nn.tanh)\n",
        "mu = denselayer(\"policy\", nn, dim_action, tf.nn.tanh)\n",
        "\n",
        "# Actions\n",
        "probs_ph = tf_normal(actions_ph, mu, sigma_sq)\n",
        "\n",
        "# NN for prediction of V\n",
        "nn  = denselayer(\"value_layer_1\", obs_ph, 64, tf.nn.relu)\n",
        "nn  = denselayer(\"value_layer_2\", nn, 64, tf.nn.relu)\n",
        "nn  = denselayer(\"value_layer_3\", nn, 64, tf.nn.relu)\n",
        "V   = denselayer(\"value\", nn, 1, None)\n",
        "\n",
        "# Get Trainable Variables\n",
        "train_vars = tf.trainable_variables()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auf2Au2__758"
      },
      "source": [
        "### Step 3: loss functions\n",
        "\n",
        "Now let's define the loss functions and constraints for actual TRPO training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EkGpySi_759"
      },
      "source": [
        "Advantage:\n",
        "$$A_{\\theta_{old}}(s_{i},a_{i})=G_{\\theta_{old}}(s_{i},a_{i})-V_{\\theta_{old}}(s_{i})$$\n",
        "\n",
        "where the gain function is\n",
        "$$G_{\\theta_{old}}(s_{i},a_{i})=\\sum_{j=i}^{T}\\gamma^{j-i}r_{j}$$\n",
        "\n",
        "The surrogate reward should be\n",
        "$$J_{surr}= {1 \\over N} \\sum\\limits_{i=0}^N \\frac{\\pi_{\\theta}(s_i, a_i)}{\\pi_{\\theta_{old}}(s_i, a_i)}\n",
        "A_{\\theta_{old}}(s_{i},a_{i})$$\n",
        "\n",
        "Clip Loss Function\n",
        "$$L_{\\theta_{old}}^{CLIP}(\\theta)=\\frac{1}{N}\\sum\\limits _{i=0}^{N}\\min\\left\\{ \\frac{\\pi_{\\theta}(s_{i},a_{i})}{\\pi_{\\theta_{old}}(s_{i},a_{i})}A_{\\theta_{old}}(s_{i},a_{i}),\\ g\\left(\\epsilon,A_{\\theta_{old}}(s_{i},a_{i})\\right)\\right\\}$$\n",
        "\n",
        "where function\n",
        "$$g(\\epsilon,A)=\\begin{cases}\n",
        "(1+\\epsilon)A & ,\\text{ if }A\\geq0\\\\\n",
        "(1-\\epsilon)A & ,\\text{ o.w.}\n",
        "\\end{cases}$$\n",
        "\n",
        "Or alternatively, minimize the surrogate loss:\n",
        "$$ L_{surr} = - L_{\\theta_{old}}^{CLIP}(\\theta) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGzd6WwT_76B"
      },
      "source": [
        "# Compute surrogate loss: negative importance-sampled policy gradient\n",
        "batch_size = tf.cast(tf.shape(mu)[0], tf.float32)\n",
        "\n",
        "# select probabilities of chosen actions\n",
        "probs_all     = tf.reshape(probs_ph, [-1])\n",
        "old_probs_all = tf.reshape(old_probs_ph, [-1])\n",
        "ratio_ph      = probs_all / old_probs_all\n",
        "\n",
        "# clipping pattern\n",
        "epsilon = 0.2\n",
        "clippling_pattern = tf.minimum((1 - epsilon) * advantage_ph, 0) +\\\n",
        "                    tf.maximum((1 + epsilon) * advantage_ph, 0)\n",
        "\n",
        "# Clipped Loss\n",
        "L_surr = tf.reduce_mean( tf.minimum(ratio_ph * advantage_ph, clippling_pattern) )\n",
        "\n",
        "\n",
        "# Value loss\n",
        "V_objective = tf.reduce_mean( tf.math.square( V[:,0] - c_returns_ph ) )\n",
        "\n",
        "ss_sq    = tf.reduce_mean( tf.math.square( old_V_ph - c_returns_ph ) )\n",
        "kl_value = tf.reduce_mean( tf.math.square( V[:0] - old_V_ph ) ) / (2 * ss_sq)\n",
        "\n",
        "V_loss = V_objective + v_beta_ph * kl_value\n",
        "train_V_loss = tf.train.AdamOptimizer(1e-4).minimize(V_loss)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imv9XYia_76F"
      },
      "source": [
        "We can ascend these gradients as long as our $\\pi_\\theta(a|s)$ satisfies the constraint\n",
        "$$E_{s,\\pi_{\\Theta_{t}}}\\Big[KL(\\pi(\\Theta_{t}, s) \\:||\\:\\pi(\\Theta_{t+1}, s))\\Big] < \\alpha$$\n",
        "\n",
        "\n",
        "\n",
        "For multivariate Guassian distributions, we have\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "KL\\left(\\pi_{t}(\\cdot|s)\\:||\\:\\pi_{t+1}(\\cdot|s)\\right)&=&\\frac{1}{2}\\left\\{ -k+Tr\\left[\\Sigma_{t+1}^{-1}\\Sigma_{t}\\right]+(\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})+\\ln\\frac{\\det(\\Sigma_{t+1})}{\\det(\\Sigma_{t})}\\right\\} \\\\(\\Sigma_{t+1}=\\Sigma_{t})&=&\\frac{1}{2}\\left\\{ (\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})\\right\\} \\\\&=&\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[\\mu_{t+1}-\\mu_{t}]_{i}}{[\\sigma_{t+1}]_{i}}\\right)^{2}\n",
        "\\end{eqnarray*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvAuUZZU_76G",
        "outputId": "b03f082b-925c-4def-a39e-bd17bc2c92e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Compute Kullback-Leibler divergence (see formula above)\n",
        "# Note: you need to sum KL and entropy over all actions, not just the ones agent took\n",
        "\n",
        "kl_policy = 0.5 * tf.reduce_sum( tf.math.square(mu - old_mu_ph) / (2 * sigma_sq))\n",
        "kl_policy /= batch_size\n",
        "\n",
        "# Compute policy entropy\n",
        "log_probs_all = tf.math.log(probs_all + 1e-5)\n",
        "entropy       = - tf.reduce_sum(probs_all * log_probs_all) / batch_size\n",
        "\n",
        "# Goal is to maximize: L_surr, minimize beta_ph * kl, maximize entropy\n",
        "# Since we use minimizer, we have\n",
        "policy_loss       = -L_surr + p_beta_ph * kl_policy - entropy\n",
        "train_Policy_loss = tf.train.AdamOptimizer(1e-4).minimize(policy_loss)\n",
        "\n",
        "# No variable depends on the following losses\n",
        "# Used only for progress tracking\n",
        "#losses = [L_surr, kl_policy, entropy, kl_value]\n",
        "losses = [kl_policy, kl_value]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BePcHv1K-u5"
      },
      "source": [
        "# Initialize TF\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjOp0ljT34VM"
      },
      "source": [
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt64G5Pi3xfO",
        "outputId": "63dbe721-69c0-4f49-878f-f07cfa0b64df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Restore variables from disk.\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, \"model.ckpt\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_rSvyFq355u"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljE2-68L_75f"
      },
      "source": [
        "### Step 2: Actions and rollouts\n",
        "\n",
        "In this section, we'll define functions that take actions $ a \\sim \\pi_\\theta(a|s) $ and rollouts $ \\langle s_0,a_0,s_1,a_1,s_2,a_2,...s_n,a_n \\rangle $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TaUC34w_75f"
      },
      "source": [
        "def act(obs, sample = True):\n",
        "    \"\"\"\n",
        "    Samples action from policy distribution (sample = True) or takes most likely action (sample = False)\n",
        "    :param: obs - single observation vector\n",
        "    :param sample: if True, samples from \\pi, otherwise takes most likely action\n",
        "    :returns: mu, V, action, prob\n",
        "    \"\"\"\n",
        "    # obs.reshape((1, -1)) makes batch first: [[obs]]\n",
        "    feed_dict = {obs_ph: obs.reshape((1, -1))}\n",
        "    mu_eval, V_eval   = sess.run([mu, V], feed_dict = feed_dict)\n",
        "    mu_eval = mu_eval[0]\n",
        "    V_eval  = V_eval[0,0]\n",
        "\n",
        "    # Sample action\n",
        "    action = sample_action(mu_eval, sigma_sq.eval()) if sample == True else mu_eval\n",
        "\n",
        "    # Add actions to the dictionary\n",
        "    feed_dict[actions_ph] = action[None]\n",
        "    prob = sess.run(probs_ph, feed_dict = feed_dict)[0]\n",
        "\n",
        "    return mu_eval, V_eval, action, prob"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX7Wf5kj_75o"
      },
      "source": [
        "Compute cummulative reward just like you did in vanilla REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDLeSmTX_75w"
      },
      "source": [
        "**Rollout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbJKrqLFCsNy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_GAE(r, v, v_p, gamma=1, gae_param=1):\n",
        "    n   = np.shape(r)[0]\n",
        "    gae = np.zeros(n, dtype=np.float32)\n",
        "\n",
        "    d = np.zeros(n, dtype = np.float32)\n",
        "    d[:-1] = r[:-1] + gamma * v[1:] - v[:-1]\n",
        "    d[-1]  = r[-1]  + gamma * v_p   - v[-1]\n",
        "    \n",
        "    gae[n-1] = d[n-1]\n",
        "    for i in reversed(range(n-1)):\n",
        "        gae[i] = d[i] + ( gae_param * gamma ) * gae[i+1]\n",
        "\n",
        "    return gae"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UFon-4g_75x"
      },
      "source": [
        "# A valid path in a rollout must either:\n",
        "# end up in a \"done\" state or\n",
        "# exceed the allowed steps\n",
        "# NOTE: We might end up with a single path that exceeds steps limit !\n",
        "\n",
        "def rollout(env, act, sample=True, gamma=1, gae_param=1, max_pathlength=3000, n_timesteps=10000):\n",
        "    \"\"\"\n",
        "    Generate rollouts for training.\n",
        "    :param: env - environment in which we will make actions to generate rollouts.\n",
        "    :param: act - the function that can return policy and action given observation.\n",
        "    :param: max_pathlength - maximum size of one path that we generate.\n",
        "    :param: n_timesteps - total sum of sizes of all pathes we generate.\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "\n",
        "    total_timesteps = 0\n",
        "\n",
        "    while total_timesteps < n_timesteps:\n",
        "        obervations, mu_evals, V_evals, actions, rewards, action_probs = [], [], [], [], [], []\n",
        "        obervation = env.reset()\n",
        "        \n",
        "        for _ in range(max_pathlength):\n",
        "            mu_eval, V_eval, action, action_prob = act(obervation, sample)\n",
        "\n",
        "            obervations.append(obervation)\n",
        "            mu_evals.append(mu_eval)\n",
        "            V_evals.append(V_eval)\n",
        "            actions.append(action)\n",
        "            action_probs.append(action_prob)\n",
        "\n",
        "            obervation, reward, done, _ = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            total_timesteps += 1\n",
        "\n",
        "            if done or total_timesteps == n_timesteps:\n",
        "                v_p = 0 if done else act(obervation)[1]\n",
        "                \n",
        "                np_values  = np.array(V_evals)\n",
        "                np_rewards = np.array(rewards)\n",
        "                \n",
        "                np_gae = get_GAE(np_rewards, np_values, v_p, gamma, gae_param)\n",
        "                cummulative_rewards = np_values + np_gae\n",
        "\n",
        "                path = {\"observations\": np.array(obervations),\n",
        "                        \"mu_evals\": np.array(mu_evals),\n",
        "                        \"values\": np_values,\n",
        "                        \"actions\": np.array(actions),\n",
        "                        \"action_probs\":  np.array(action_probs),\n",
        "                        \"cumulative_returns\": cummulative_rewards,\n",
        "                        \"GAE\": np_gae,\n",
        "                        \"reward\": np.sum(np_rewards),\n",
        "                        }\n",
        "                paths.append(path)\n",
        "                break\n",
        "    # outputs List of Dictionaries (feed to nn)\n",
        "    return paths"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrH9E9sk_76c"
      },
      "source": [
        "##### Step 5: Main PPO loop\n",
        "\n",
        "Here we will train our network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiROykhhcUp-"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import trange\n",
        "import pickle\n",
        "\n",
        "eps = 0.01\n",
        "\n",
        "gamma     = 0.99\n",
        "gae_param = 0.95\n",
        "\n",
        "p_beta = 100\n",
        "v_beta = 100\n",
        "\n",
        "# Number of Gradient descent iterations for policy\n",
        "grad_iters = 5\n",
        "\n",
        "# To store average reward history of last few episodes\n",
        "avg_reward_list = []\n",
        "std_reward_list = []\n",
        "\n",
        "#Load \n",
        "with open(\"avg_reward_list.txt\", \"rb\") as fp:   # Unpickling\n",
        "    avg_reward_list = pickle.load(fp)\n",
        "\n",
        "with open(\"std_reward_list.txt\", \"rb\") as fp:   # Unpickling\n",
        "    std_reward_list = pickle.load(fp)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgJmJFz1_76d",
        "outputId": "18db7d94-f83c-4664-b7a3-2cb5dc1ada5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "#import time\n",
        "#from itertools import count\n",
        "#from collections import OrderedDict\n",
        "#num_epis_total = 0    # number of played episodes\n",
        "#start_time = time.time()\n",
        "\n",
        "\n",
        "done_iters = len(avg_reward_list)\n",
        "iters  = 100\n",
        "x_axis = list( range(1,done_iters + 1) )\n",
        "\n",
        "for i in trange(iters):\n",
        "\n",
        "    # Generating paths.\n",
        "    paths = rollout(env, act, sample=True, gamma=gamma, gae_param=gae_param)\n",
        "    \n",
        "    # Load feed_dict and old_weights\n",
        "    observations = np.concatenate([path[\"observations\"] for path in paths])\n",
        "    old_mu_eval  = np.concatenate([path[\"mu_evals\"] for path in paths])\n",
        "    old_V_eval   = np.concatenate([path[\"values\"] for path in paths])\n",
        "    actions      = np.concatenate([path[\"actions\"] for path in paths])\n",
        "    old_probs    = np.concatenate([path[\"action_probs\"] for path in paths])\n",
        "    c_returns    = np.concatenate([path[\"cumulative_returns\"] for path in paths])\n",
        "    GAE          = np.concatenate([path[\"GAE\"] for path in paths])\n",
        "    \n",
        "    feed_dict_policy = {obs_ph: observations,\n",
        "                        old_mu_ph: old_mu_eval,\n",
        "                        actions_ph: actions,\n",
        "                        old_probs_ph: old_probs,\n",
        "                        advantage_ph: GAE,\n",
        "                        c_returns_ph: c_returns,\n",
        "                        p_beta_ph: p_beta,}\n",
        "\n",
        "    for _ in range(grad_iters):\n",
        "        # Train Policy loss\n",
        "        sess.run(train_Policy_loss, feed_dict = feed_dict_policy)\n",
        "\n",
        "    feed_dict_value = {obs_ph: observations,\n",
        "                       c_returns_ph: c_returns,\n",
        "                       old_V_ph: old_V_eval,\n",
        "                       v_beta_ph: v_beta}\n",
        "\n",
        "    for _ in range(grad_iters):\n",
        "        # Train State Value loss\n",
        "        sess.run(train_V_loss, feed_dict = feed_dict_value)\n",
        "    \n",
        "    feed_dict_loss = feed_dict_policy\n",
        "    for k in feed_dict_value.keys():\n",
        "        feed_dict_loss[k] = feed_dict_value[k]\n",
        "\n",
        "    # Report current progress\n",
        "    kl_policy_v, kl_value_v = sess.run(losses, feed_dict = feed_dict_loss)\n",
        "    \n",
        "    # Update soft constraint regulizers\n",
        "    if kl_policy_v >= 1.5 * eps:\n",
        "        p_beta *= 2\n",
        "    if kl_policy_v <= eps / 1.5:\n",
        "        p_beta /= 2\n",
        "\n",
        "    if kl_value_v >= 1.5 * eps:\n",
        "        v_beta *= 2\n",
        "    if kl_value_v <= eps / 1.5:\n",
        "        v_beta /= 2\n",
        "    \n",
        "    episode_rewards = np.array([path[\"reward\"] for path in paths])\n",
        "    \n",
        "    avg_reward_list.append(episode_rewards.mean())\n",
        "    std_reward_list.append(episode_rewards.std())\n",
        "\n",
        "    #Print Figure\n",
        "    x_axis.append(done_iters + i + 1)\n",
        "\n",
        "    clear_output(True)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle('Mean and Std Reward')\n",
        "    ax1.plot(x_axis, avg_reward_list)\n",
        "    ax2.plot(x_axis, std_reward_list)\n",
        "    ax1.set(xlabel='Episode', ylabel='Mean Reward')\n",
        "    ax2.set(xlabel='Episode', ylabel='Std Reward')\n",
        "    fig.tight_layout(pad=3.0)\n",
        "    plt.show()\n",
        "\n",
        "    #stats = OrderedDict()\n",
        "    #num_epis_total += len(episode_rewards)\n",
        "\n",
        "    #stats[\"Total number of episodes\"] = num_epis_total\n",
        "    #stats[\"Average sum of rewards per episode\"] = episode_rewards.mean()\n",
        "    #stats[\"Std of rewards per episode\"] = episode_rewards.std()\n",
        "    #stats[\"Entropy\"] = entropy\n",
        "    #stats[\"Time elapsed\"] = \"%.2f mins\" % ((time.time() - start_time)/60.)\n",
        "    #stats[\"KL between old and new distribution\"] = kl\n",
        "    #stats[\"Surrogate loss\"] = L_surr\n",
        "\n",
        "    #for k, v in stats.items():\n",
        "    #    print(k + \": \" + \" \" * (40 - len(k)) + str(v))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [1:10:22<00:00, 42.22s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYNm-Ga_q36w"
      },
      "source": [
        "# Save to disk\n",
        "saver = tf.train.Saver()\n",
        "saver.save(sess, \"model.ckpt\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(\"avg_reward_list.txt\", \"wb\") as fp:\n",
        "    pickle.dump(avg_reward_list, fp)\n",
        "\n",
        "with open(\"std_reward_list.txt\", \"wb\") as fp:\n",
        "    pickle.dump(std_reward_list, fp)    "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_T5qDKCx17K",
        "outputId": "5c9cc16b-df3e-412f-c680-c0f590a4006a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "paths = rollout(env, act, sample=True)\n",
        "print(np.mean([path['reward'] for path in paths]))\n",
        "\n",
        "x = [path['reward'] for path in paths]\n",
        "plt.hist(x, bins = 50)\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.01464785448503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPLklEQVR4nO3df6zdd13H8eeLlo5EYAN7waU/aBc7YiMG5mXOgDIZajtIayIhXURAgSbEEZBF0zkzzfyHMQNCMsUGkB8CswwcN1AyBIckxpbdARu0tXA3wN5uuG780ITIbHj7x/kOzu7uvee0O7fn9OPzkZz0++Ozc1779PbV7/l+z/k2VYUk6ez3uHEHkCSNhoUuSY2w0CWpERa6JDXCQpekRqwe1wuvXbu2Nm3aNK6Xl6Sz0h133PFAVU0ttm9shb5p0yZmZ2fH9fKSdFZK8q2l9nnKRZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDViYKEneU+S+5N8dYn9SfKOJHNJ7kpy0ehjSpIGGeYI/b3AtmX2bwe2dI/dwN889liSpFM1sNCr6vPAd5YZshN4f/UcAM5Lcv6oAkqShjOKb4quA471rc932+5bODDJbnpH8WzcuPG0X3DTnk8uuv2bb37xaT9na5yj07fU3MGpz9+k/T6MMs+4/t+W+/1ZzKTlgZXLdEYvilbV3qqarqrpqalFb0UgSTpNoyj048CGvvX13TZJ0hk0ikKfAV7RfdrlEuD7VfWo0y2SpJU18Bx6kg8DlwJrk8wDfwY8HqCq3gnsBy4H5oAfAL+3UmElSUsbWOhVdcWA/QX8wcgSSZJOi98UlaRGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDViqEJPsi3J0SRzSfYssn9jktuSfCnJXUkuH31USdJyBhZ6klXAjcB2YCtwRZKtC4b9KbCvqp4D7AL+etRBJUnLG+YI/WJgrqruqaqHgJuAnQvGFPDkbvlc4N7RRZQkDWOYQl8HHOtbn++29ftz4OVJ5oH9wOsXe6Iku5PMJpk9ceLEacSVJC1lVBdFrwDeW1XrgcuBDyR51HNX1d6qmq6q6ampqRG9tCQJhiv048CGvvX13bZ+rwb2AVTVvwFPANaOIqAkaTjDFPrtwJYkm5OsoXfRc2bBmP8ALgNI8nP0Ct1zKpJ0Bg0s9Ko6CVwJ3AocofdplkNJrkuyoxt2FfDaJHcCHwZeVVW1UqElSY+2ephBVbWf3sXO/m3X9i0fBp432miSpFPhN0UlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjRiq0JNsS3I0yVySPUuMeVmSw0kOJfnQaGNKkgZZPWhAklXAjcCvA/PA7Ulmqupw35gtwNXA86rqu0metlKBJUmLG+YI/WJgrqruqaqHgJuAnQvGvBa4saq+C1BV9482piRpkGEKfR1wrG99vtvW70LgwiT/muRAkm2jCihJGs7AUy6n8DxbgEuB9cDnkzyrqr7XPyjJbmA3wMaNG0f00pIkGO4I/TiwoW99fbet3zwwU1X/W1XfAL5Gr+Afoar2VtV0VU1PTU2dbmZJ0iKGKfTbgS1JNidZA+wCZhaMuYXe0TlJ1tI7BXPPCHNKkgYYWOhVdRK4ErgVOALsq6pDSa5LsqMbdivwYJLDwG3AH1XVgysVWpL0aEOdQ6+q/cD+Bduu7Vsu4E3dQ5I0Bn5TVJIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGjFUoSfZluRokrkke5YZ99tJKsn06CJKkoYxsNCTrAJuBLYDW4ErkmxdZNyTgDcAB0cdUpI02DBH6BcDc1V1T1U9BNwE7Fxk3F8A1wP/M8J8kqQhDVPo64Bjfevz3bYfS3IRsKGqPrncEyXZnWQ2yeyJEydOOawkaWmP+aJokscBbwWuGjS2qvZW1XRVTU9NTT3Wl5Yk9Rmm0I8DG/rW13fbHvYk4OeBzyX5JnAJMOOFUUk6s4Yp9NuBLUk2J1kD7AJmHt5ZVd+vqrVVtamqNgEHgB1VNbsiiSVJixpY6FV1ErgSuBU4AuyrqkNJrkuyY6UDSpKGs3qYQVW1H9i/YNu1S4y99LHHkiSdKr8pKkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWrEUIWeZFuSo0nmkuxZZP+bkhxOcleSzyZ5xuijSpKWM7DQk6wCbgS2A1uBK5JsXTDsS8B0Vf0CcDPwllEHlSQtb5gj9IuBuaq6p6oeAm4CdvYPqKrbquoH3eoBYP1oY0qSBhmm0NcBx/rW57ttS3k18KnFdiTZnWQ2yeyJEyeGTylJGmikF0WTvByYBm5YbH9V7a2q6aqanpqaGuVLS9L/e6uHGHMc2NC3vr7b9ghJXgRcA7ygqn44mniSpGENc4R+O7AlyeYka4BdwEz/gCTPAf4W2FFV948+piRpkIGFXlUngSuBW4EjwL6qOpTkuiQ7umE3AE8EPpLky0lmlng6SdIKGeaUC1W1H9i/YNu1fcsvGnEuSdIp8puiktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUiKEKPcm2JEeTzCXZs8j+c5L8Q7f/YJJNow4qSVrewEJPsgq4EdgObAWuSLJ1wbBXA9+tqp8F3gZcP+qgkqTlDXOEfjEwV1X3VNVDwE3AzgVjdgLv65ZvBi5LktHFlCQNkqpafkDyUmBbVb2mW/9d4Jeq6sq+MV/txsx363d3Yx5Y8Fy7gd3d6jOBo6eYdy3wwMBRk8O8K8u8K8u8K+t08z6jqqYW27H6seU5NVW1F9h7uv99ktmqmh5hpBVl3pVl3pVl3pW1EnmHOeVyHNjQt76+27bomCSrgXOBB0cRUJI0nGEK/XZgS5LNSdYAu4CZBWNmgFd2yy8F/rkGncuRJI3UwFMuVXUyyZXArcAq4D1VdSjJdcBsVc0A7wY+kGQO+A690l8Jp326ZkzMu7LMu7LMu7JGnnfgRVFJ0tnBb4pKUiMsdElqxMQXepJnJzmQ5MtJZpNc3G1Pknd0txu4K8lF4876sCSvT/LvSQ4leUvf9qu7vEeT/OY4My6U5KoklWRttz6R85vkhm5u70ryj0nO69s3kfM76NYZ45ZkQ5Lbkhzufmbf0G1/apJ/SvL17tenjDtrvySrknwpySe69c3drUfmuluRrBl3xn5Jzktyc/fzeyTJL498jqtqoh/Ap4Ht3fLlwOf6lj8FBLgEODjurF2uXwM+A5zTrT+t+3UrcCdwDrAZuBtYNe68XbYN9C56fwtYO+Hz+xvA6m75euD6SZ5feh8kuBu4AFjTZdw67lwLMp4PXNQtPwn4WjefbwH2dNv3PDzXk/IA3gR8CPhEt74P2NUtvxN43bgzLsj7PuA13fIa4LxRz/HEH6EDBTy5Wz4XuLdb3gm8v3oOAOclOX8cARd4HfDmqvohQFXd323fCdxUVT+sqm8Ac/RuqzAJ3gb8Mb25fthEzm9VfbqqTnarB+h9LwImd36HuXXGWFXVfVX1xW75v4EjwDoeeUuP9wG/NZ6Ej5ZkPfBi4F3deoAX0rv1CExe3nOBX6X3iUCq6qGq+h4jnuOzodDfCNyQ5Bjwl8DV3fZ1wLG+cfPdtnG7EPiV7q3fvyR5brd9IvMm2Qkcr6o7F+yayLwL/D69dxEwuXknNdeiujulPgc4CDy9qu7rdn0bePqYYi3mr+gdhPyoW/9p4Ht9f9lP2jxvBk4Af9edJnpXkp9ixHN8Rr/6v5QknwF+ZpFd1wCXAX9YVR9N8jJ6f8O96EzmW2hA3tXAU+mdpngusC/JBWcw3qMMyPsn9E5jTIzl8lbVx7sx1wAngQ+eyWwtS/JE4KPAG6vqv/rvr1dVlWQiPuOc5CXA/VV1R5JLx51nSKuBi4DXV9XBJG+nd4rlx0YxxxNR6FW1ZEEneT/whm71I3RvsRjulgQrYkDe1wEfq95JsS8k+RG9m/BMXN4kz6J35HBn94d3PfDF7sLzxOV9WJJXAS8BLuvmGcaYd4BJzfUISR5Pr8w/WFUf6zb/Z5Lzq+q+7nTb/Us/wxn1PGBHksuBJ9A7Jft2eqcFV3dH6ZM2z/PAfFUd7NZvplfoI53js+GUy73AC7rlFwJf75ZngFd0n8a4BPh+31uXcbqF3oVRklxI7+LHA/Ty7krvHwPZDGwBvjC2lEBVfaWqnlZVm6pqE70fuouq6ttM6Pwm2UbvrfaOqvpB366Jm9/OMLfOGKvu/PO7gSNV9da+Xf239Hgl8PEznW0xVXV1Va3vfmZ30bvVyO8At9G79QhMUF6A7s/UsSTP7DZdBhxm1HM87iu/Q1wZfj5wB71PBxwEfrHbHnr/8MbdwFeA6XFnrZ9cvf574KvAF4EX9u27pst7lO6TO5P0AL7JTz7lMqnzO0fvnPSXu8c7J31+6X1i6GtdtmvGnWeRfM+nd0H8rr55vZzeeenP0juI+gzw1HFnXST7pfzkUy4X0PtLfI7eu/lzxp1vQdZnA7PdPN8CPGXUc+xX/yWpEWfDKRdJ0hAsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktSI/wMUnC+WHtcHGAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEBoGP13IoC8"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KXLiWZYben0"
      },
      "source": [
        "def evaluate(env, n_games=1):\n",
        "    \"\"\"Plays an a game from start till done, returns per-game rewards \"\"\"\n",
        "\n",
        "    game_rewards = []\n",
        "    for _ in range(n_games):\n",
        "        # initial observation and memory\n",
        "        observation = env.reset()\n",
        "\n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            mu_eval, V_eval, action, prob = act(observation, sample=True)\n",
        "            observation, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        game_rewards.append(total_reward)\n",
        "    return game_rewards"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6bjqpBtl9_c",
        "outputId": "d4e2ff97-79db-4337-dbaa-80d02e870a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gym.wrappers\n",
        "\n",
        "with gym.wrappers.Monitor(env, directory=\"videos\", force=True) as env_monitor:\n",
        "    final_rewards = evaluate(env_monitor, n_games=5)\n",
        "\n",
        "print(\"Final rewards\", np.mean(final_rewards))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final rewards 4.292314397598757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IXb-scZdj2I"
      },
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(video_names[-1]))  # You can also try other indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6mISEoL_76h"
      },
      "source": [
        "# Homework option I: better sampling (10+pts)\n",
        "\n",
        "In this section, you're invited to implement a better rollout strategy called _vine_.\n",
        "\n",
        "![img](https://s17.postimg.cc/i90chxgvj/vine.png)\n",
        "\n",
        "In most gym environments, you can actually backtrack by using states. You can find a wrapper that saves/loads states in [the mcts seminar](https://github.com/yandexdataschool/Practical_RL/blob/master/week10_planning/seminar_MCTS.ipynb).\n",
        "\n",
        "You can read more about in the [TRPO article](https://arxiv.org/abs/1502.05477) in section 5.2.\n",
        "\n",
        "The goal here is to implement such rollout policy (we recommend using tree data structure like in the seminar above).\n",
        "Then you can assign cummulative rewards similar to `get_cummulative_rewards`, but for a tree.\n",
        "\n",
        "__bonus task__ - parallelize samples using multiple cores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJsr6IU_76h"
      },
      "source": [
        "# Homework option II (10+pts)\n",
        "\n",
        "Let's use TRPO to train evil robots! (pick any of two)\n",
        "* [MuJoCo robots](https://gym.openai.com/envs#mujoco)\n",
        "* [Box2d robot](https://gym.openai.com/envs/BipedalWalker-v2)\n",
        "\n",
        "The catch here is that those environments have continuous action spaces. \n",
        "\n",
        "Luckily, TRPO is a policy gradient method, so it's gonna work for any parametric $\\pi_\\theta(a|s)$. We recommend starting with gaussian policy:\n",
        "\n",
        "$$\\pi_\\theta(a|s) = N(\\mu_\\theta(s),\\sigma^2_\\theta(s)) = {1 \\over \\sqrt { 2 \\pi {\\sigma}_{\\theta(s)}^{2} } } e^{ (a - \n",
        "\\mu_\\theta(s))^2 \\over 2 {\\sigma}_{\\theta(s)}^{2} } $$\n",
        "\n",
        "In the $\\sqrt { 2 \\pi {\\sigma}_{\\theta(s)}^{2} }$ clause, $\\pi$ means ~3.1415926, not agent's policy.\n",
        "\n",
        "This essentially means that you will need two output layers:\n",
        "* $\\mu_\\theta(s)$, a dense layer with linear activation\n",
        "* ${\\sigma^2}_\\theta(s)$, a dense layer with activation tf.exp (to make it positive; like rho from bandits)\n",
        "\n",
        "For multidimensional actions, you can use fully factorized gaussian (basically a vector of gaussians). Namely,\n",
        "\n",
        "The Multivariate Gaussian distribution has a pdf that reads \n",
        "$$p(x\\ |\\ \\mu,\\Sigma)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\det(\\Sigma)^{1/2}}\\exp\\left\\{ -\\frac{1}{2}\\left(x-\\mu\\right)^{T}\\Sigma^{-1}\\left(x-\\mu\\right)\\right\\}$$\n",
        "_\n",
        "\n",
        "In the case when the covariance matrix is diagonal $\\Sigma=\\mathrm{diag}(\\sigma_{1}^{2},\\dots,\\sigma_{k}^{2})$, the pdf simplifies to \n",
        "$$p(x\\ |\\ \\mu,\\sigma)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\prod_{i=1}^{k}\\sigma_{i}}\\exp\\left\\{ -\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{x_{i}-\\mu_{i}}{\\sigma_{i}}\\right)^{2}\\right\\}$$\n",
        "_\n",
        "\n",
        "Assuming $\\mu_{\\theta}:S\\rightarrow\\mathbb{R}^{k}$\n",
        "and $\\sigma_{\\theta}:S\\rightarrow\\mathbb{R}^{k}$ are functions parameterized by $\\theta$, we obtain a model-based policy of the form:\n",
        "$$\\pi_{\\theta}(a|s)=\\mathcal{N}\\left(\\mu_{\\theta}(s),\\sigma_{\\theta}^{2}(s)\\right)=\\frac{1}{(2\\pi)^{k/2}\\cdot\\prod_{i=1}^{k}[\\sigma_{\\theta}(s)]_{i}}\\exp\\left\\{ -\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[a]_{i}-[\\mu_{\\theta}(s)]_{i}}{[\\sigma_{\\theta}(s)]_{i}}\\right)^{2}\\right\\}.$$\n",
        "_\n",
        "\n",
        "Notice that\n",
        "$$\\ln\\pi_{\\theta}(a|s)=-\\frac{k}{2}\\ln(2\\pi)-\\sum_{i=1}^{k}\\ln[\\sigma_{\\theta}(s)]_{i}-\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[a]_{i}-[\\mu_{\\theta}(s)]_{i}}{[\\sigma_{\\theta}(s)]_{i}}\\right)^{2}$$\n",
        " \n",
        "\n",
        "\n",
        "For multivariate Guassian distributions, we have\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "KL\\left(\\pi_{t}(\\cdot|s)\\:||\\:\\pi_{t+1}(\\cdot|s)\\right)&=&\\frac{1}{2}\\left\\{ -k+Tr\\left[\\Sigma_{t+1}^{-1}\\Sigma_{t}\\right]+(\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})+\\ln\\frac{\\det(\\Sigma_{t+1})}{\\det(\\Sigma_{t})}\\right\\} \\\\(\\Sigma_{t+1}=\\Sigma_{t})&=&\\frac{1}{2}\\left\\{ (\\mu_{t+1}-\\mu_{t})^{T}\\Sigma_{t+1}^{-1}(\\mu_{t+1}-\\mu_{t})\\right\\} \\\\&=&\\frac{1}{2}\\sum_{i=1}^{k}\\left(\\frac{[\\mu_{t+1}-\\mu_{t}]_{i}}{[\\sigma_{t+1}]_{i}}\\right)^{2}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "\n",
        "__bonus task__: compare performance of continuous action space method to action space discretization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmMETkn13ERp"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def normal(s, mu, sigma_sq):\n",
        "    a = np.exp( - np.square(s - mu) / (2 * sigma_sq) )\n",
        "    b = 1 / np.sqrt(2 * sigma_sq * np.pi)\n",
        "    return a*b\n",
        "\n",
        "mu = 0\n",
        "sigma = 0.1\n",
        "sigma_sq = np.square(sigma)\n",
        "\n",
        "x = normal(mu, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "# pdf\n",
        "pdf = [normal(mu + i/1000, mu, sigma_sq) for i in range(-100,100)]\n",
        "plt.plot(pdf)\n",
        "plt.show()\n",
        "\n",
        "# histogram of samples\n",
        "samples = mu + sigma * np.random.randn(10000)\n",
        "hist = plt.hist(samples, 100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDtAOru4E4FO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPg-zzzQV883"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "\n",
        "dim_action = 2\n",
        "\n",
        "@tf.function\n",
        "def tf_normal(s, mu, sigma_sq):\n",
        "    exp_term   = tf.math.exp( - tf.reduce_sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = tf.math.sqrt( tf.math.pow(2 * np.pi, dim_action) * tf.reduce_prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "\n",
        "s        = 0.9 * tf.ones( (2,3,dim_action), dtype = tf.float32 )\n",
        "mu       = tf.ones( (2,3,dim_action), dtype = tf.float32 )\n",
        "sigma_sq = (0.1)**2 * tf.ones((2,3,dim_action), dtype = tf.float32)\n",
        "\n",
        "\n",
        "x = tf_normal(s, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "y = multivariate_normal.pdf( s[0,0], mu[0,0], sigma_sq[0,0] )\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWUHEZE4dZtt"
      },
      "source": [
        "def normal(s, mu, sigma_sq):\n",
        "    exp_term   = np.exp( - np.sum( tf.math.square(s - mu) / (2 * sigma_sq), axis = -1) )\n",
        "    norm_const = np.sqrt( np.pow(2 * np.pi, dim_action) * np.prod(sigma_sq, axis=-1) )\n",
        "    return exp_term / norm_const\n",
        "\n",
        "s        = 0.9 * np.ones( (2,3,dim_action), dtype = np.float32 )\n",
        "mu       = np.ones( (2,3,dim_action), dtype = np.float32 )\n",
        "sigma_sq = (0.1)**2 * np.ones((2,3,dim_action), dtype = np.float32)\n",
        "\n",
        "\n",
        "x = tf_normal(s, mu, sigma_sq)\n",
        "print(x)\n",
        "\n",
        "y = multivariate_normal.pdf( s[0,0], mu[0,0], sigma_sq[0,0] )\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_YHQlGWd2Rb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}